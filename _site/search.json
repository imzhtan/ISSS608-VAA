[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Name: Tan Zhi Hao\nCourse: ISSS608-Visual Analytics and Applications-G1\nTerm: Jan-Apr 2023"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(tidyverse)\n\n\n\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "pacman::p_load(ggstatsplot, tidyverse, tidyverse,plotly, crosstalk, DT, ggdist, gganimate, gifski, gapminder, FunnelPlotR, plotly, knitr)\n\n\nexam <- read_csv(\"data/Exam_data.csv\")\n\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English score\"\n)\n\n\n\n\n\nggbetweenstats(\n  data = exam,\n  x = GENDER,\n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\nggbetweenstats(\n  data = exam,\n  x = RACE,\n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE,\n  pairwise.comparisons = TRUE,\n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE\n)\n\n\n\n\n\nexam1 <- exam %>%\n  mutate(MATHS_bins = \n           cut(MATHS,\n               breaks = c(0,60,75,85,100))\n         )\n\n\nggbarstats(exam1,\n           x = MATHS_bins,\n           y = GENDER)\n\n\n\n\n\npacman::p_load(readxl, performance, parameters, see)\n\n\ncar_resale <- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model       Price Age_0…¹ Mfg_M…² Mfg_Y…³     KM Quart…⁴ Weight Guara…⁵\n   <dbl> <chr>       <dbl>   <dbl>   <dbl>   <dbl>  <dbl>   <dbl>  <dbl>   <dbl>\n 1    81 TOYOTA Cor… 18950      25       8    2002  20019     100   1180       3\n 2     1 TOYOTA Cor… 13500      23      10    2002  46986     210   1165       3\n 3     2 TOYOTA Cor… 13750      23      10    2002  72937     210   1165       3\n 4     3  TOYOTA Co… 13950      24       9    2002  41711     210   1165       3\n 5     4 TOYOTA Cor… 14950      26       7    2002  48000     210   1165       3\n 6     5 TOYOTA Cor… 13750      30       3    2002  38500     210   1170       3\n 7     6 TOYOTA Cor… 12950      32       1    2002  61000     210   1170       3\n 8     7  TOYOTA Co… 16900      27       6    2002  94612     210   1245       3\n 9     8 TOYOTA Cor… 18600      30       3    2002  75889     210   1245       3\n10    44 TOYOTA Cor… 16950      27       6    2002 110404     234   1255       3\n# … with 1,426 more rows, 28 more variables: HP_Bin <chr>, CC_bin <chr>,\n#   Doors <dbl>, Gears <dbl>, Cylinders <dbl>, Fuel_Type <chr>, Color <chr>,\n#   Met_Color <dbl>, Automatic <dbl>, Mfr_Guarantee <dbl>,\n#   BOVAG_Guarantee <dbl>, ABS <dbl>, Airbag_1 <dbl>, Airbag_2 <dbl>,\n#   Airco <dbl>, Automatic_airco <dbl>, Boardcomputer <dbl>, CD_Player <dbl>,\n#   Central_Lock <dbl>, Powered_Windows <dbl>, Power_Steering <dbl>,\n#   Radio <dbl>, Mistlamps <dbl>, Sport_Model <dbl>, Backseat_Divider <dbl>, …\n\n\n\nmodel <- lm(Price ~ Age_08_04 + Mfg_Year + KM +\n              Weight + Guarantee_Period, data = car_resale)\n\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Guarantee_Period  1.04   [1.01, 1.17]         1.02      0.97     [0.86, 0.99]\n        Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n         Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\nHigh Correlation\n\n   Term  VIF   VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n     KM 1.46 [1.37, 1.57]         1.21      0.68     [0.64, 0.73]\n Weight 1.41 [1.32, 1.51]         1.19      0.71     [0.66, 0.76]\n\n\n\ncheck_c <- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\nmodel1 <- lm(Price ~ Age_08_04 + KM + \n               Weight + Guarantee_Period, data = car_resale)\n\n\ncheck_n <- check_normality(model1)\n\n\nplot(check_n)\n\n\n\n\n\ncheck_h <- check_heteroscedasticity(model1)\n\n\nplot(check_h)\n\n\n\n\n\ncheck_model(model1)\n\n\n\n\n\nplot(parameters(model1))\n\n\n\n\n\nggcoefstats(model1,\n            output = \"plot\")\n\n\n\n\n\nexam <- read_csv(\"data/Exam_data.csv\")\n\n\nmy_sum <- exam %>%\n  group_by(RACE) %>%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS),\n    lci = t.test(MATHS, conf.level = 0.95)$conf.int[1],\n    uci = t.test(MATHS, conf.level = 0.95)$conf.int[2]\n  ) %>%\n  mutate(se=sd/sqrt(n-1))\n\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n \n  \n    RACE \n    n \n    mean \n    sd \n    lci \n    uci \n    se \n  \n \n\n  \n    Chinese \n    193 \n    76.50777 \n    15.69040 \n    74.28011 \n    78.73544 \n    1.132357 \n  \n  \n    Indian \n    12 \n    60.66667 \n    23.35237 \n    45.82928 \n    75.50406 \n    7.041005 \n  \n  \n    Malay \n    108 \n    57.44444 \n    21.13478 \n    53.41288 \n    61.47601 \n    2.043177 \n  \n  \n    Others \n    9 \n    69.66667 \n    10.72381 \n    61.42362 \n    77.90971 \n    3.791438 \n  \n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE,\n        ymin=mean-se,\n        ymax=mean+se),\n    width=0.2,\n    colour='black',\n    alpha=0.9,\n    size=0.5) +\n  geom_point(aes\n            (x=RACE,\n            y=mean),\n            stat = \"identity\",\n            color = \"red\",\n            size = 1.5,\n            alpha = 1) +\n  ggtitle(\"Standard error of mean maths score by race\")\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE,\n        ymin=lci,\n        ymax=uci),\n    width=0.2,\n    colour='black',\n    alpha=0.9,\n    size=0.5) +\n  geom_point(aes\n            (x=RACE,\n            y=mean),\n            stat = \"identity\",\n            color = \"red\",\n            size = 1.5,\n            alpha = 1) +\n  ggtitle(\"95% confidence interval of mean maths score by race\")\n\n\n\n\n\nexam %>%\n  ggplot(aes(x = RACE,\n             y = MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\", subtitle = \"Mean Point + Multuple-interval plot\"\n  )\n\n\n\n\n\nexam %>%\n  ggplot(aes(x = RACE, y=MATHS)) +\n  stat_pointinterval(.width = 0.95,\n                     .point = median,\n                     .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\", subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\nexam %>%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval(\n    show.legend = FALSE) +   \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\nexam %>%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")\n\n\n\n\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\n\nlibrary(ungeviz)\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, width = 0.05), \n    size = 0.4, color = \"#0072B2\", alpha = 1/2) +\n  geom_hpline(data = sampler(25, group = RACE), height = 0.6, color = \"#D55E00\") +\n  theme_bw() + \n  # `.draw` is a generated column indicating the sample draw\n  transition_states(.draw, 1, 3)\n\n\n\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"#D55E00\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)\n\n\n\n\n\ncovid19 <- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %>%\n  mutate_if(is.character, as.factor)\n\n\nfunnel_plot(\n  numerator = covid19$Positive,\n  denominator = covid19$Death,\n  group = covid19$`Sub-district`\n)\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\nfunnel_plot(\n  numerator = covid19$Death,\n  denominator = covid19$Positive,\n  group = covid19$`Sub-district`,\n  data_type = \"PR\",\n  xrange = c(0, 6500),\n  yrange = c(0, 0.05)\n)\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\nfunnel_plot(\n  numerator = covid19$Death,\n  denominator = covid19$Positive,\n  group = covid19$`Sub-district`,\n  data_type = \"PR\",   \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #<<           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #<<\n  y_label = \"Cumulative Fatality Rate\"  #<<\n)\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\ndf <-  covid19 %>%\n  mutate(rate = Death / Positive) %>%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %>%\n  filter(rate > 0)\n\n\nfit.mean <- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\nnumber.seq <- seq(1, max(df$Positive), 1)\nnumber.ll95 <- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 <- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 <- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 <- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI <- data.frame(number.ll95, number.ul95, number.ll999, number.ul999, number.seq, fit.mean)\n\n\np <- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np\n\n\n\n\n\nfp_ggplotly <- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on Exercise 05",
    "section": "",
    "text": "pacman::p_load(corrplot, tidyverse, ggstatsplot, ggtern, plotly, seriation, dendextend, heatmaply, GGally, parallelPlot)\n\n\nCorrelogram\n\nwine <- read_csv(\"data/wine_quality.csv\")\n\n\npairs(wine[,1:11])\n\n\n\n\n\npairs(wine[,2:12])\n\n\n\n\n\npairs(wine[,2:12], upper.panel = NULL)\n\n\n\n\n\npairs(wine[,2:12], lower.panel = NULL)\n\n\n\n\n\npanel.cor <- function(x, y, digits=2, prefix=\"\", cex.cor, ...) {\nusr <- par(\"usr\")\non.exit(par(usr))\npar(usr = c(0, 1, 0, 1))\nr <- abs(cor(x, y, use=\"complete.obs\"))\ntxt <- format(c(r, 0.123456789), digits=digits)[1]\ntxt <- paste(prefix, txt, sep=\"\")\nif(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)\ntext(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[,2:12], \n      upper.panel = panel.cor)\n\n\n\n\n\n##| fig-width: 7\n##| fig-height: 7\n\n#ggstatsplot::ggcorrmat(\n#  data = wine, \n#  cor.vars = 1:11,\n#  ggcorrplot.args = list(outline.color = \"black\", \n#                         hc.order = TRUE,\n#                         tl.cex = 10,\n#                         lab_size = 3),\n#  title    = \"Correlogram for wine dataset\",\n#  subtitle = \"Four pairs are no significant at p < 0.05\"\n#)\n\n\nwine.cor <- cor(wine[, 1:11])\n\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\nTernary\n\npop_data <- read_csv(\"data/respopagsex2000to2018_tidy.csv\") \n\n\nagpop_mutated <- pop_data %>%\n  mutate(`Year` = as.character(Year))%>%\n  spread(AG, Population) %>%\n  mutate(YOUNG = rowSums(.[4:8]))%>%\n  mutate(ACTIVE = rowSums(.[9:16]))  %>%\n  mutate(OLD = rowSums(.[17:21])) %>%\n  mutate(TOTAL = rowSums(.[22:24])) %>%\n  filter(Year == 2018)%>%\n  filter(TOTAL > 0)\n\n\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()\n\n\n\n\n\n\nHeatmap\n\nwh <- read_csv(\"data/WHData-2018.csv\")\n\n\nrow.names(wh) <- wh$Country\n\n\nwh1 <- dplyr::select(wh, c(3, 7:12))\nwh_matrix <- data.matrix(wh)\n\n\nwh_heatmap <- heatmap(wh_matrix,\n                      Rowv=NA, Colv=NA)\n\n\n\n\n\nwh_heatmap <- heatmap(wh_matrix)\n\n\n\n\n\nwh_heatmap <- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))\n\n\n\n\n\nheatmaply(mtcars)\n\n\n\n\n\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])\n\n\n\n\n\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )\n\n\n\n\n\n\n\nParallel Coordinates Plots\n\nwh <- read_csv(\"data/WHData-2018.csv\")\n\n\nggparcoord(data = wh, \n           columns = c(7:12))\n\n\n\n\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\")\n\n\n\n\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region)\n\n\n\n\n\nhistoVisibility <- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06-VisTime.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06-VisTime.html",
    "title": "Hands-on Exercise 6: Visualising and Analysing Time-oriented Data",
    "section": "",
    "text": "By the end of this hands-on exercise you will be able create the followings data visualisation by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a horizon chart"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06-VisTime.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06-VisTime.html#getting-started",
    "title": "Hands-on Exercise 6: Visualising and Analysing Time-oriented Data",
    "section": "Getting Started",
    "text": "Getting Started\n::: callout-info ## Do It Yourself Write a code chunk to check, install and launch the following R packages: scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table and tidyverse.\n\n\nShow the code\npacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, tidyverse, readxl, knitr, data.table)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06-VisTime.html#plotting-calendar-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06-VisTime.html#plotting-calendar-heatmap",
    "title": "Hands-on Exercise 6: Visualising and Analysing Time-oriented Data",
    "section": "Plotting Calendar Heatmap",
    "text": "Plotting Calendar Heatmap\nIn this section, you will learn how to plot a calender heatmap programmetically by using ggplot2 package.\n\nBy the end of this section, you will be able to:\n\nplot a calender heatmap by using ggplot2 functions and extension,\nto write function using R programming,\nto derive specific date and time related field by using base R and lubridate packages\nto perform data preparation task by using tidyr and dplyr packages.\n\n\nThe Data\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\n\nImporting the data\nFirst, you will use the code chunk below to import eventlog.csv file into R environment and called the data frame as attacks.\n\nattacks <- read_csv(\"data/eventlog.csv\")\n\n\n\nExamining the data structure\nIt is always a good practice to examine the imported data frame before further analysis is performed.\nFor example, kable() can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\n\ntz field stores time zone of the source IP address.\n\n\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\n\n\nData Preparation\nStep 1: Deriving weekday and hour of day fields\nBefore we can plot the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\n\nmake_hr_wkday <- function(ts, sc, tz) {\n  real_times <- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt <- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\nNote: ymd_hms() and hour() are from lubridate package and weekdays() is a base R function.\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels <- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks <- attacks %>%\n  group_by(tz) %>%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %>% \n  ungroup() %>% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\nNote: Beside extracting the necessary data into attacks data frame, mutate() of dplyr package is used to convert wkday and hour fields into factor so they’ll be ordered when plotting\nTable below shows the tidy tibble table after processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\nBuilding the Calendar Heatmaps\n\ngrouped <- attacks %>% \n  count(wkday, hour) %>% \n  ungroup() %>%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\nThings to learn from the code chunk: - a tibble data table called grouped is derived by aggregating the attack by wkday and hour fields. - a new field called n is derived by using group_by() and count() functions. - na.omit() is used to exclude missing value. - geom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles. - theme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot. - coord_equal() is used to ensure the plot will have an aspect ratio of 1:1. - scale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\n\n\n\n\nThen we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there’s no need to further preprocess the data.\n\n\nBuilding Multiple Calendar Heatmaps\nChallenge: Building multiple heatmaps for the top four countries with the highest number of attacks.\n\n\n\nPlotting Multiple Calendar Heatmaps\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, you are required to do the followings:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country <- count(\n  attacks, source_country) %>%\n  mutate(percent = percent(n/sum(n))) %>%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\nIn this step, you are required to extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\ntop4 <- attacks_by_country$source_country[1:4]\ntop4_attacks <- attacks %>%\n  filter(source_country %in% top4) %>%\n  count(source_country, wkday, hour) %>%\n  ungroup() %>%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %>%\n  na.omit()\n\n\n\nPlotting Multiple Calendar Heatmaps\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06-VisTime.html#cycle-plot",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06-VisTime.html#cycle-plot",
    "title": "Hands-on Exercise 6: Visualising and Analysing Time-oriented Data",
    "section": "Cycle Plot",
    "text": "Cycle Plot\nIn this section, you will learn how to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n\n\nData Preparation\n\nStep 1: Data Import\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair <- read_excel(\"data/arrivals_by_air.xlsx\")\n\n\n\nStep 2: Deriving month and year fields\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month <- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year <- year(ymd(air$`Month-Year`))\n\n\n\nStep 4: Extracting the target country\nNext, the code chunk below is use to extract data for the target country (i.e. Vietnam)\n\nVietnam <- air %>% \n  select(`Vietnam`, \n         month, \n         year) %>%\n  filter(year >= 2010)\n\n\n\nStep 5: Computing year average arrivals by month\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data <- Vietnam %>% \n  group_by(month) %>%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\n\nPlotting the cycle plot\nThe code chunk below is used to plot the cycle plot as shown in Slide 12/23.\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "Installing and loading R packages\nTwo packages will be installed and loaded. They are: tidyverse, ggiraph.\n\npacman::p_load(ggiraph, tidyverse)\n\nImporting data\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\n\nggplot(data = exam_data,\n       aes(x = MATHS)) +\n  geom_dotplot(dotsize = 0.5)\n\n\n\n\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "pacman::p_load(plotly, DT, patchwork, ggstatsplot, tidyverse, readxl, performance, parameters, see)\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\n\nplot_ly(data = exam_data,\n        x = ~ENGLISH,\n        y = ~MATHS,\n        color = ~RACE)\n\n\n\n\n\n\np <- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(dotsize = 1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\nggplotly(p)\n\n\n\n\n\n\nggbetweenstats(\n  data = exam_data,\n  x = GENDER,\n  y = MATHS,\n  type = \"p\",\n  messages = FALSE\n)\n\n\n\n\n\nggscatterstats(\n  data = exam_data,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = TRUE,\n  )\n\n\n\n\n\ncar_resale <- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model       Price Age_0…¹ Mfg_M…² Mfg_Y…³     KM Quart…⁴ Weight Guara…⁵\n   <dbl> <chr>       <dbl>   <dbl>   <dbl>   <dbl>  <dbl>   <dbl>  <dbl>   <dbl>\n 1    81 TOYOTA Cor… 18950      25       8    2002  20019     100   1180       3\n 2     1 TOYOTA Cor… 13500      23      10    2002  46986     210   1165       3\n 3     2 TOYOTA Cor… 13750      23      10    2002  72937     210   1165       3\n 4     3  TOYOTA Co… 13950      24       9    2002  41711     210   1165       3\n 5     4 TOYOTA Cor… 14950      26       7    2002  48000     210   1165       3\n 6     5 TOYOTA Cor… 13750      30       3    2002  38500     210   1170       3\n 7     6 TOYOTA Cor… 12950      32       1    2002  61000     210   1170       3\n 8     7  TOYOTA Co… 16900      27       6    2002  94612     210   1245       3\n 9     8 TOYOTA Cor… 18600      30       3    2002  75889     210   1245       3\n10    44 TOYOTA Cor… 16950      27       6    2002 110404     234   1255       3\n# … with 1,426 more rows, 28 more variables: HP_Bin <chr>, CC_bin <chr>,\n#   Doors <dbl>, Gears <dbl>, Cylinders <dbl>, Fuel_Type <chr>, Color <chr>,\n#   Met_Color <dbl>, Automatic <dbl>, Mfr_Guarantee <dbl>,\n#   BOVAG_Guarantee <dbl>, ABS <dbl>, Airbag_1 <dbl>, Airbag_2 <dbl>,\n#   Airco <dbl>, Automatic_airco <dbl>, Boardcomputer <dbl>, CD_Player <dbl>,\n#   Central_Lock <dbl>, Powered_Windows <dbl>, Power_Steering <dbl>,\n#   Radio <dbl>, Mistlamps <dbl>, Sport_Model <dbl>, Backseat_Divider <dbl>, …\n\n\n\nmodel <- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Guarantee_Period  1.04   [1.01, 1.17]         1.02      0.97     [0.86, 0.99]\n        Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n         Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\nHigh Correlation\n\n   Term  VIF   VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n     KM 1.46 [1.37, 1.57]         1.21      0.68     [0.64, 0.73]\n Weight 1.41 [1.32, 1.51]         1.19      0.71     [0.66, 0.76]\n\n\n\ncheck_c <- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\nmodel1 <- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\n\ncheck_n <- check_normality(model1)\n\n\nplot(check_n)\n\n\n\n\n\ncheck_h <- check_heteroscedasticity(model1)\n\n\nplot(check_h)\n\n\n\n\n\ncheck_model(model1)\n\n\n\n\n\nggcoefstats(model1, \n            output = \"plot\")\n\n\n\n\n\nmy_sum <- exam_data %>%\n  group_by(RACE) %>%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %>%\n  mutate(se=sd/sqrt(n-1))\n\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n \n  \n    RACE \n    n \n    mean \n    sd \n    se \n  \n \n\n  \n    Chinese \n    193 \n    76.50777 \n    15.69040 \n    1.132357 \n  \n  \n    Indian \n    12 \n    60.66667 \n    23.35237 \n    7.041005 \n  \n  \n    Malay \n    108 \n    57.44444 \n    21.13478 \n    2.043177 \n  \n  \n    Others \n    9 \n    69.66667 \n    10.72381 \n    3.791438 \n  \n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean \n          maths score by rac\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In-class Exercise 05",
    "section": "",
    "text": "pacman::p_load(corrplot, tidyverse, ggstatsplot, ggtern, plotly, seriation, dendextend, heatmaply, GGally, parallelPlot)\n\n\nCorrelogram\n\nwine <- read_csv(\"data/wine_quality.csv\")\n\n\npairs(wine[,1:11])\n\n\n\n\n\npairs(wine[,2:12])\n\n\n\n\n\npairs(wine[,2:12], upper.panel = NULL)\n\n\n\n\n\npairs(wine[,2:12], lower.panel = NULL)\n\n\n\n\n\npanel.cor <- function(x, y, digits=2, prefix=\"\", cex.cor, ...) {\nusr <- par(\"usr\")\non.exit(par(usr))\npar(usr = c(0, 1, 0, 1))\nr <- abs(cor(x, y, use=\"complete.obs\"))\ntxt <- format(c(r, 0.123456789), digits=digits)[1]\ntxt <- paste(prefix, txt, sep=\"\")\nif(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)\ntext(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[,2:12], \n      upper.panel = panel.cor)\n\n\n\n\n\n##| fig-width: 7\n##| fig-height: 7\n\n#ggstatsplot::ggcorrmat(\n#  data = wine, \n#  cor.vars = 1:11,\n#  ggcorrplot.args = list(outline.color = \"black\", \n#                         hc.order = TRUE,\n#                         tl.cex = 10,\n#                         lab_size = 3),\n#  title    = \"Correlogram for wine dataset\",\n#  subtitle = \"Four pairs are no significant at p < 0.05\"\n#)\n\n\nwine.cor <- cor(wine[, 1:11])\n\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\nTernary\n\npop_data <- read_csv(\"data/respopagsex2000to2018_tidy.csv\") \n\n\nagpop_mutated <- pop_data %>%\n  mutate(`Year` = as.character(Year))%>%\n  spread(AG, Population) %>%\n  mutate(YOUNG = rowSums(.[4:8]))%>%\n  mutate(ACTIVE = rowSums(.[9:16]))  %>%\n  mutate(OLD = rowSums(.[17:21])) %>%\n  mutate(TOTAL = rowSums(.[22:24])) %>%\n  filter(Year == 2018)%>%\n  filter(TOTAL > 0)\n\n\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()\n\n\n\n\n\n\nHeatmap\n\nwh <- read_csv(\"data/WHData-2018.csv\")\n\n\nrow.names(wh) <- wh$Country\n\n\nwh1 <- dplyr::select(wh, c(3, 7:12))\nwh_matrix <- data.matrix(wh)\n\n\nwh_heatmap <- heatmap(wh_matrix,\n                      Rowv=NA, Colv=NA)\n\n\n\n\n\nwh_heatmap <- heatmap(wh_matrix)\n\n\n\n\n\nwh_heatmap <- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))\n\n\n\n\n\nheatmaply(mtcars)\n\n\n\n\n\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])\n\n\n\n\n\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )\n\n\n\n\n\n\n\nParallel Coordinates Plots\n\nwh <- read_csv(\"data/WHData-2018.csv\")\n\n\nggparcoord(data = wh, \n           columns = c(7:12))\n\n\n\n\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\")\n\n\n\n\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region)\n\n\n\n\n\nhistoVisibility <- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "Welcome to ISSS608 Visual Analytics and Applications. In this website, you will find my coursework prepared for this course."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "1. Introduction\nIn this exercise, I created a 3x3 trellis view dashboard of the Age-Sex pyramid of Singapore’s resident population for 9 of the 55 planning areas in Singapore for 2022. The data is a CSV file extracted from Singstat website named ‘respopagesextod2022’.\n\n\n\nFigure 1: A snapshot of the dataset used\n\n\nI created a multi-select filter card for planning area so that we can choose whichever 9 planning areas we want to visualize but for the analysis I chose 9 specific planning areas as described in Section 3.\n\n\n2. Step-by-step procedure\n\n\n\n\n\n\n\n\nNo.\nStep\nScreenshot\n\n\n\n\n1\nLoad the excel file into Tableau. Drag ‘respopagesextod2022’ worksheet into the main pane under Data Source. Rename the variables accordingly (e.g. from AG to ‘Age Group’).\nNote: Not much pre-cleaning of the data is necessary for this exercise, as the aggregations (e.g. sum of population count by gender, age group, planning area) will automatically be done by Tableau when the graphs are created. The default data types will also not impact the final visualization (e.g. year is not used).\n\n\n\n2\nCreate a new sheet. We start by creating just 1 Age-Sex pyramid for the whole resident population first.\nClick on the down arrow as shown in red circle in the the screenshot and create calculated fields ‘CountFemales’ and ‘CountMales’ using the formula in the screenshot.\n\n\n\n\n3\nDrag ‘Age Group’ into the Rows field and ‘CountMales’ and ‘CountFemales’ into the Columns field.\n\n\n\n4\nRight click on ‘CountMales’ on the horizontal axis and click ‘Edit Axis’. Select ‘Reversed’ under Scale.\n\n\n\n5\nTo filter only 9 planning areas, drag ‘Planning Areas’ to the Filters box. Randomly select 9 planning areas first.\n\n\n\n6\nClick on the arrow in the ‘Planning areas’ pill and select ‘Show Filter’ to display the filter card so that you can select any planning areas you wish to visualize later on.\n\n\n\n7\nUnder Marks box -> ‘Sum(CountFemales)’, click on ‘Color’ and select the desired color to differentiate the sexes by color.\n\n\n\n8\nNext, we create the Trellis View. Create a new calculated field, ‘Index’ using the formula shown in the screenshot.\n\n\n\n9\nCreate a new parameter called ‘# of Columns’, choose Data Type ‘Integer and input ’3’ under Current Value. This is because we want to have a 3 x 3 Trellis View.\n\n\n\n10\nCreate 2 new calculated fields, ‘Rows’ and ‘Columns’ using the formulas shown in the screenshot.\nAfter creating these new variables, click on the down arrow when hovering over them on the left panel and convert to ‘discrete’.\n\n\n\n11\nDrag ‘Rows’ into the Rows field and ‘Columns’ into the Columns field. Drag ‘Planning Area’ into the Label box under Marks -> All.\n\n\n\n12\nClick on the down arrow in the ‘Columns’ pill in the Columns field and select Compute Using -> Planning Area.\nDo the same for the ‘Rows’ pill in the Rows field.\n\n\n\n13\nNext, we move on to labeling the planning areas.\nFirst, un-check ‘Show mark labels’ by clicking on Label under Marks -> All.\nNote: I’m doing it in a slightly different way, so that the Planning Area can be in a column on its own. However, I’ve also prepared the standard version where the label appears on the top right (simply allow label overlap, always show label for one of the bars and click and move it around). The instructions below are for the non-standard way.\n\n\n\n14\nCreate a new variable directly within the Columns field by double-clicking on an empty space within it. Type in ‘AVG(0)’. Drag the newly created pill to the left of the SUM(CountMales) pill.\n\n\n\n15\nUnder Marks -> AGG(AVG(0)), change the type to ‘Line’ and the Opacity to 0%.\n\n\n\n16\nDrag ‘Planning Area’ to Label under Marks -> AGG(AVG(0)). Select ‘Line Ends’ under ‘Marks to label’ and un-check ‘Label end of line’.\n\n\n\n17\nLastly, improve the aesthetics.\nHide the headers on the top and left by right-clicking and de-selecting ‘Show Header’.\n\n\n\n18\nChange the order of Age Group by Data source order so that youngest Age Group is at the bottom and oldest at the top.\n\n\n\n19\nChange the title of the sheet by clicking on the title field or changing it dynamically in the sheet name.\nChange the labels on the horizontal axis by right-clicking on them.\n\n\n\n20\nAdd or delete information in the tooltip under Marks -> All -> Tooltip.\n\n\n\n21\nCreate a new dashboard ‘Dashboard 1’, drag ‘Age-Sex Pyramid for Selected Planning Areas in Singapore, 2022’ into the pane.\nIn this case, as we only have one visualization in the dashboard, there is no need to add title text or make other changes.\n\n\n\n22\nAdjust the size of charts, dashboard, etc. for better presentation. Extract data if necessary. Click Server -> Tableau Public -> Save to Tableau Public’ for publishing.\nLinks to my Tableau Public visualizations:\n\nPlanning area in a column on its own: Link\nStandard version where planning area is on the top right of each pyramid: Link\n\n\n\n\n\n\n\n3. Write-up on Patterns observed from visualization\nFor the pattern analysis, I selected 9 planning areas (PA) split equally by 3 market segments as defined by the Urban Redevelopment Authority (URA):\n\nCore Central Region (CCR): Bukit Timah, Newton, Novena\nRest of Central Region (RCR): Bishan, Toa Payoh, Queenstown\nOutside Central Region (OCR): Jurong East, Tampines, Yishun\n\n\n\n\nFigure 2: Trellis view of the Age-Sex pyramids for 9 selected planning areas\n\n\n(1) For almost all the PA, there seems to be several horizontal peak and troughs. The age groups between 55 to 69, as well as age groups between 25 to 39 are the peaks while the other age groups are the troughs. This is reflective of the Baby Boomers (around age 59-77) and their children (Millennials around age 27-42), which have relatively more births compared to the other generations.\n(2) In general, more people live in the OCR compared to the RCR which in turn has more people compared to the CCR. This could be reflective of the ratio of residences compared to other infrastructure in the different regions, as well as affordability. We can see that the age-sex pyramids are widest for Tampines and Yishun, and narrowest for Newtown and Novena, while the rest are in between. We note that there are some minor exceptions such as Bishan (RCR), Bukit Timah (CCR) and Jurong East (OCR) being quite similar to each other due to proportion of residences, but this does not cause the overall trend to deviate greatly.\n(3) The Sex distribution seems to be relatively evenly distributed for most age groups (with slightly more females than males) except for those aged 75 and above where the difference is more pronounced. This could be due to higher life expectancy for females compared to males, which are 85.9 and 81.1 respectively for Singapore residents in 2021.\n(4) For PAs in the RCR and OCR, the largest or second largest age group is 30-34. However, the largest age group for PAs in the CCR is 45-49. This could be because residences for PAs in CCR are more expensive compared to other market segments and, generally, those aged 45-49 would have higher income and spending power compared to the younger age groups and be able to afford living in the CCR.\n(5) There are signs of a shrinking population, with the age groups within 0 to 19 smaller than the earlier generations, with the exception of those above 70. The top and bottom ends of the pyramid are the narrowest. It is understandable that there would be fewer people in the older age groups as they pass on. However, the pattern also shows that there are fewer young people and we could gradually see an aging population as the baby boomers move into their senior years. Unless the trends are reversed, the Millennials (children of the Baby Boomers) could be the last sizeable age group."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take-home Exercise 02",
    "section": "",
    "text": "This exercise is based on a take-home exercise 1 submission prepared by a classmate. The peer submission will be critiqued in terms of clarity and aesthetics, and the original design will be remade using the data visualization principles and best practices learnt in Lessons1 and 2.\nThe dataset used in take-home exercises 1 and 2 is a CSV file extracted from Singstat website named ‘respopagesextod2022’ and processed by RStudio tidyverse family of packages and visualized by ggplot2 and its extensions."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#install-and-launching-r-packages",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#install-and-launching-r-packages",
    "title": "Take-home Exercise 02",
    "section": "2.1 Install and launching R packages",
    "text": "2.1 Install and launching R packages\nThe code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\n\nCode\npacman::p_load(tidyverse)\n\nlibrary(plotly)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-the-data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-the-data",
    "title": "Take-home Exercise 02",
    "section": "2.2 Importing the data",
    "text": "2.2 Importing the data\nThe code chunk below imports respopagesextod2022.csv from the data folder into R by using read_csv() of readr and save it as an tibble data frame called pop_data.\n\n\nCode\npop_data <- read_csv(\"data/respopagesextod2022.csv\")\nhead(pop_data)\n\n\n# A tibble: 6 × 7\n  PA         SZ                     AG     Sex   TOD                   Pop  Time\n  <chr>      <chr>                  <chr>  <chr> <chr>               <dbl> <dbl>\n1 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HDB 1- and 2-Room …     0  2022\n2 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HDB 3-Room Flats       10  2022\n3 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HDB 4-Room Flats       10  2022\n4 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HDB 5-Room and Exe…    30  2022\n5 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HUDC Flats (exclud…     0  2022\n6 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males Condominiums and O…    50  2022"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#ordering-age-group",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#ordering-age-group",
    "title": "Take-home Exercise 02",
    "section": "2.3 Ordering Age Group",
    "text": "2.3 Ordering Age Group\nThe code chunk below orders the Age groups sequentially, by planning area, age group and sex.\n\n\nCode\npop_data$AG <- gsub(\"_\", \" \", \n                    pop_data$AG, \n                    fixed = TRUE)\n\nag_order <- c(\"0 to 4\", \"5 to 9\", \"10 to 14\", \"15 to 19\", \"20 to 24\", \"25 to 29\", \"30 to 34\", \"35 to 39\", \"40 to 44\", \"45 to 49\", \"50 to 54\", \"55 to 59\", \"60 to 64\", \"65 to 69\", \"70 to 74\", \"75 to 79\", \"80 to 84\", \"85 to89\", \"90 and over\")\n\npop_ordered <- pop_data %>%\n  group_by(`PA`, `AG`,`Sex`) %>%\n  summarise(`Count` = sum(`Pop`)) %>%\n  mutate(AG = factor(AG, levels = ag_order)) %>%\n  arrange(AG) %>%\n  ungroup()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#filtering-planning-areas",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#filtering-planning-areas",
    "title": "Take-home Exercise 02",
    "section": "2.4 Filtering Planning Areas",
    "text": "2.4 Filtering Planning Areas\nIt looks like ZeXeong selected the planning areas based on the top 9 population sizes. The code chunk below filters these 9 planning areas.\n\n\nCode\nt9_pa <- pop_data %>%\n  group_by(`PA`) %>%\n  summarise(`Count` = sum(`Pop`)) %>%\n  ungroup()\n\nt9 <- arrange(t9_pa, desc(t9_pa$Count)) %>%\n  slice(1:9) %>%\n  select(`PA`)\n\nt9_only1 <- pop_ordered %>% \n  filter(pop_ordered$PA %in% t9$PA)\n\nt9_only = na.omit(t9_only1)\n\nhead(t9_only)\n\n\n# A tibble: 6 × 4\n  PA            AG     Sex     Count\n  <chr>         <fct>  <chr>   <dbl>\n1 Bedok         0 to 4 Females  4970\n2 Bedok         0 to 4 Males    5090\n3 Choa Chu Kang 0 to 4 Females  4080\n4 Choa Chu Kang 0 to 4 Males    4260\n5 Hougang       0 to 4 Females  4430\n6 Hougang       0 to 4 Males    4520"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#critique-of-grid-facet-to-display-population-pyramids-in-a-row",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#critique-of-grid-facet-to-display-population-pyramids-in-a-row",
    "title": "Take-home Exercise 02",
    "section": "3.1 Critique of Grid Facet to Display Population Pyramids in a Row",
    "text": "3.1 Critique of Grid Facet to Display Population Pyramids in a Row\n\n\n\nFigure 1: Original design by classmate row Trellis\n\n\n\n3.1.1 Critique\n\n3.1.1.1 Clarity\nWhat works:\n(A) As there are only 9 planning areas, this grid facet to display the pyramids in a row works as we can clearly see the side by side comparison of each planning area.\n(B)The planning area labels are clearly stated at the top of each planning area.\nWhat doesn’t work and why:\n(A) Title\n\nThe title does not provide sufficient detail about the data being visualized. It simply states ‘Compare the Feasibility for Visual Analysis by Two Trellis Layouts of 9 Population Pyramids’. It does not tell us the data is for which country’s population and for which year. A more appropriate title will be ‘Age-Sex Pyramid in Singapore, 2022’\n(B) Axes\nThe x-axis does not have a label telling us what is the information being shown. It is also not shown at the bottom of the dashboard. The legend at the bottom shows us which color represents which sex but it is insufficient to tell us is this a count or proportion, nor does it tell us the units. In general, if the word ‘count’ is used (e.g. Male Count), this tells us it is a number.\n(C) Grid\nWith an x-axis values, it would also be good to include vertical grid lines as the x-axis values are in continuous numbers.\n\n\n3.1.1.2 Aesthetics\nWhat doesn’t work and why:\n(A) Colour\n\nThe colors used to represent Male and Female are not intuitive. By convention, Blue is used to represent Male and Red/Pink is used to represent Female. Of course, this is only based on convention and not a hard rule, but for people who are used to the conventional colors, at first glance, we may think that the right side of the pyramids are representing Males, but it is actually representing Females.\nThe horizontal alternating color shading (i.e. grey-white-grey-white) in the background does not seem to be necessary as the age groups are grouped as ‘discrete horizontal bars’ and not ‘continuous’. The alternating shading also seem to be missing for the left side of each pyramid, which may be distracting.\n(B) Data labels\nThe labels for the count being displayed overlapping the bars can make the charts very messy. It may also be hard to read the numbers for the top of the pyramids where the bars are short. Some solutions are to either display the numbers outside the bar (non-overlapping), change the numbers to thousands using ‘k’, and the best would be not to display the numbers at all since there is already a tooltip displaying information as you hover over the bars.\n\n\n\n3.1.2 Remake\n\nChanged title to ‘Age-Sex Pyramid in Singapore, 2022’.\nAdded a x-axis label ‘Population Count’ as well as the x-axis values of up to 15k on each side in steps of 5k as well as grid lines for more clarity.\nChanged the colors of the bars to Blue for ‘Males’ and Pink for ‘Females’. Removed alternating background shading.\nRemoved count value label display for each bar.\nIn the tooltip, unnecessary information is removed. When hovering over ‘Females’, only the AG, sex and count for Females are shown and similarly for ‘Males’.\n\n\n\nCode\nAgSxPyr_t9_row <- ggplot(t9_only, aes(x = AG, y = Count, fill = Sex)) +\n  geom_bar(data = subset(t9_only, \n                         Sex == \"Males\"), \n           aes(x = AG, \n               y = -Count, \n               fill = Sex), \n           stat = \"identity\" \n          ) +\n  geom_bar(data = subset(t9_only, \n                         Sex == \"Females\"), \n           aes(x = AG, \n               y = Count, \n               fill = Sex), \n           stat = \"identity\" \n           ) +\n  scale_y_continuous(breaks = seq(-15000, 15000, 5000), \n                     labels = paste0(\n                       as.character(\n                         c(seq(15, 0, -5), \n                           seq(5, 15, 5))),\n                       \"k\")) +\n  coord_flip() +\n  facet_grid(~ PA) +\n  labs (y = \"Population Count\", \n        x = \"Age Group (AG)\", \n        title = 'Age-Sex Pyramid in Singapore, 2022') +\n  theme_bw() +\n  theme(axis.ticks.y = element_blank()) +\n  scale_fill_manual(values = c(\"Males\" = \"lightblue\", \n                               \"Females\" = \"lightpink\")) \n\nggplotly(AgSxPyr_t9_row, \n         session = \"knitr\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#critique-of-wrap-facet-to-display-population-pyramids-3-by-3-matrix",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#critique-of-wrap-facet-to-display-population-pyramids-3-by-3-matrix",
    "title": "Take-home Exercise 02",
    "section": "3.2 Critique of Wrap Facet to Display Population Pyramids 3 by 3 Matrix",
    "text": "3.2 Critique of Wrap Facet to Display Population Pyramids 3 by 3 Matrix\n\n\n\nFigure 2: Original design by classmate 3x3 Trellis\n\n\n\n3.2.1 Critique\n\n3.2.1.1 Clarity\nWhat works and doesn’t work in point 3.1.1.1 for the ‘Grid Facet in a row’ all apply to this 3x3 Trellis as well.\n\n\n3.2.1.2 Aesthetics\nWhat works and doesn’t work in point 3.1.1.2 for the ‘Grid Facet in a row’ all apply to this 3x3 Trellis as well.\nIn addition, it would be good to remove unnecessary information to avoid confusion in the tooltip such as the ‘Column along PA’ and ‘Row along PA’. We can also remove ‘Male Population’ when hovering over Female and remove ‘Female Population’ when hovering over ‘Male’\n\n\n\n3.2.2 Remake\n\nChanged title to ‘Age-Sex Pyramid in Singapore, 2022’.\nAdded a x-axis label ‘Population Count’ as well as the x-axis values of up to 15k on each side in steps of 5k as well as grid lines for more clarity.\nChanged the colors of the bars to Blue for ‘Males’ and Pink for ‘Females’. Removed alternating horizontal shading.\nRemoved count value label display for each bar.\nIn the tooltip, unnecessary information is removed. ‘Column along PA’ and ‘Row along PA’ are removed. When hovering over ‘Females’, only the AG, sex and count for Females are shown and similarly for ‘Males’.\nThe labels for Planning Area are now at the middle top of each micro-chart in the Trellis display.\n\nSketch of the remake using Powerpoint:\n\nActual remake using ggplot2, ggplot2 extensions and tidyverse packages:\n\n\nCode\nAgSxPyr_t9_wrap <- ggplot(t9_only, aes(x = AG, y = Count, fill = Sex)) +\n  geom_bar(data = subset(t9_only, \n                         Sex == \"Males\"), \n           aes(x = AG, \n               y = -Count, \n               fill = Sex), \n           stat = \"identity\" \n           ) +\n  geom_bar(data = subset(t9_only, \n                         Sex == \"Females\"), \n           aes(x = AG, \n               y = Count, \n               fill = Sex), \n           stat = \"identity\" \n          ) +\n  scale_y_continuous(breaks = seq(-15000, 15000, 5000), \n                     labels = paste0(\n                       as.character(\n                         c(seq(15, 0, -5), \n                           seq(5, 15, 5))),\n                       \"k\")) +\n  coord_flip() +\n  facet_wrap(~ PA) +\n  labs (y = \"Population Count\", \n        x = \"Age Group (AG)\", \n        title = 'Age-Sex Pyramid in Singapore, 2022') +\n  theme_bw() +\n  theme(axis.ticks.y = element_blank()) +\n  scale_fill_manual(values = c(\"Males\" = \"lightblue\", \n                               \"Females\" = \"lightpink\")) \n\nggplotly(AgSxPyr_t9_wrap, \n         session = \"knitr\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Take-home Exercise 03",
    "section": "",
    "text": "In this take-home exercise, I will uncover the salient patterns of the resale prices of public housing property by residential towns in Singapore by using appropriate analytical visualisation techniques learned in Lesson 4: Fundamentals of Visual Analytics.\nFor the purpose of this study, the focus will be on 3-ROOM, 4-ROOM and 5-ROOM types. The study period will be on 2022.\nResale flat princes based on registration date from Jan-2017 onwards from Data.gov.sg will be used to prepare the analytical visualisation and processed by RStudio tidyverse family of packages and visualized by ggplot2 and its extensions as well as other R packages."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#installing-and-launching-r-packages",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#installing-and-launching-r-packages",
    "title": "Take-home Exercise 03",
    "section": "2.1 Installing and launching R packages",
    "text": "2.1 Installing and launching R packages\nThe code chunk below uses p_load() of pacman package to check if the various packages used for the visual analysis are installed in the computer. If they are, then they will be launched into R.\n\n\nCode\npacman::p_load(ggstatsplot, tidyverse, readxl, performance, parameters, see, plotly, crosstalk, DT, ggdist, gganimate, gifski, gapminder)\n\nlibrary(plotly)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#importing-the-data",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#importing-the-data",
    "title": "Take-home Exercise 03",
    "section": "2.2 Importing the data",
    "text": "2.2 Importing the data\nThe code chunk below imports resale-flat-prices-based-on-registration-date-from-jan-2017-onwards.csv from the data folder into R by using read_csv() of readr and save it as an tibble data frame called resale_data.\n\n\nCode\nresale_data <- read_csv(\"data/resale-flat-prices-based-on-registration-date-from-jan-2017-onwards.csv\")\n\nhead(resale_data)\n\n\n# A tibble: 6 × 11\n  month   town     flat_…¹ block stree…² store…³ floor…⁴ flat_…⁵ lease…⁶ remai…⁷\n  <chr>   <chr>    <chr>   <chr> <chr>   <chr>     <dbl> <chr>     <dbl> <chr>  \n1 2017-01 ANG MO … 2 ROOM  406   ANG MO… 10 TO …      44 Improv…    1979 61 yea…\n2 2017-01 ANG MO … 3 ROOM  108   ANG MO… 01 TO …      67 New Ge…    1978 60 yea…\n3 2017-01 ANG MO … 3 ROOM  602   ANG MO… 01 TO …      67 New Ge…    1980 62 yea…\n4 2017-01 ANG MO … 3 ROOM  465   ANG MO… 04 TO …      68 New Ge…    1980 62 yea…\n5 2017-01 ANG MO … 3 ROOM  601   ANG MO… 01 TO …      67 New Ge…    1980 62 yea…\n6 2017-01 ANG MO … 3 ROOM  150   ANG MO… 01 TO …      68 New Ge…    1981 63 yea…\n# … with 1 more variable: resale_price <dbl>, and abbreviated variable names\n#   ¹​flat_type, ²​street_name, ³​storey_range, ⁴​floor_area_sqm, ⁵​flat_model,\n#   ⁶​lease_commence_date, ⁷​remaining_lease"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-wrangling",
    "title": "Take-home Exercise 03",
    "section": "2.3 Data wrangling",
    "text": "2.3 Data wrangling\n\na) Filtering\nThe code chunk below filters for 3, 4 and 5 room flat types and for year 2022.\n\n\n\nCode\nresale_data_filter <- resale_data %>%\n  separate(month, into = c(\"year\", \"month\"), sep = \"-\") %>%\n  filter(year == \"2022\") %>%\n  filter(flat_type %in% c(\"3 ROOM\", \"4 ROOM\", \"5 ROOM\"))\n\nhead(resale_data_filter)\n\n\n# A tibble: 6 × 12\n  year  month town       flat_type block stree…¹ store…² floor…³ flat_…⁴ lease…⁵\n  <chr> <chr> <chr>      <chr>     <chr> <chr>   <chr>     <dbl> <chr>     <dbl>\n1 2022  01    ANG MO KIO 3 ROOM    320   ANG MO… 07 TO …      73 New Ge…    1977\n2 2022  01    ANG MO KIO 3 ROOM    225   ANG MO… 07 TO …      67 New Ge…    1978\n3 2022  01    ANG MO KIO 3 ROOM    331   ANG MO… 07 TO …      68 New Ge…    1981\n4 2022  01    ANG MO KIO 3 ROOM    534   ANG MO… 07 TO …      82 New Ge…    1980\n5 2022  01    ANG MO KIO 3 ROOM    578   ANG MO… 04 TO …      67 New Ge…    1980\n6 2022  01    ANG MO KIO 3 ROOM    452   ANG MO… 01 TO …      83 New Ge…    1979\n# … with 2 more variables: remaining_lease <chr>, resale_price <dbl>, and\n#   abbreviated variable names ¹​street_name, ²​storey_range, ³​floor_area_sqm,\n#   ⁴​flat_model, ⁵​lease_commence_date\n\n\n\n\nb) Converting variable and datatype\nThe code chunk below converts the remaining lease from months and years (in the character datatype) to months (in the numeric datatype).\n\n\nCode\nresale_data_lease1 <- resale_data_filter %>%\nseparate(remaining_lease, into = c(\"years\", \"months\"), sep = \" years \") %>%\n separate(years, into = c(\"years\", \"test1\"), sep = \" \") %>%\n  separate(months, into = c(\"months\", \"test2\"), sep = \" \") %>%\n  transform(years = as.numeric(years)) %>%\n  transform(months = as.numeric(months)) %>%\n  replace(is.na(.), 0) %>%\n  transform(rem_lease_inmonths = months + (years * 12))\n  \nresale_data_lease <- subset(resale_data_lease1, select = -c(test1, test2))\n\nhead(resale_data_lease)\n\n\n  year month       town flat_type block       street_name storey_range\n1 2022    01 ANG MO KIO    3 ROOM   320  ANG MO KIO AVE 1     07 TO 09\n2 2022    01 ANG MO KIO    3 ROOM   225  ANG MO KIO AVE 1     07 TO 09\n3 2022    01 ANG MO KIO    3 ROOM   331  ANG MO KIO AVE 1     07 TO 09\n4 2022    01 ANG MO KIO    3 ROOM   534 ANG MO KIO AVE 10     07 TO 09\n5 2022    01 ANG MO KIO    3 ROOM   578 ANG MO KIO AVE 10     04 TO 06\n6 2022    01 ANG MO KIO    3 ROOM   452 ANG MO KIO AVE 10     01 TO 03\n  floor_area_sqm     flat_model lease_commence_date years months resale_price\n1             73 New Generation                1977    54      5       358000\n2             67 New Generation                1978    55      1       355000\n3             68 New Generation                1981    58      0       338000\n4             82 New Generation                1980    57      2       420000\n5             67 New Generation                1980    57      1       328000\n6             83 New Generation                1979    56      7       360000\n  rem_lease_inmonths\n1                653\n2                661\n3                696\n4                686\n5                685\n6                679\n\n\n\n\nc) Ordering\n\nThe code chunk below changes the storey range into a factor variable such that it’s ordered.\n\n\nCode\nstorey_order <- c(\"01 TO 03\", \"04 TO 06\", \"07 TO 09\", \"10 TO 12\", \"13 TO 15\", \"16 TO 18\", \"19 TO 21\", \"22 TO 24\", \"25 TO 27\", \"28 TO 30\", \"31 TO 33\", \"34 TO 36\", \"37 TO 39\", \"40 TO 42\", \"43 TO 45\", \"46 TO 48\", \"49 TO 51\")\n\nresale_data_order <- resale_data_lease %>% \n  mutate(`storey_range` = factor(storey_range, levels = storey_order))\n\nhead(resale_data_order)\n\n\n  year month       town flat_type block       street_name storey_range\n1 2022    01 ANG MO KIO    3 ROOM   320  ANG MO KIO AVE 1     07 TO 09\n2 2022    01 ANG MO KIO    3 ROOM   225  ANG MO KIO AVE 1     07 TO 09\n3 2022    01 ANG MO KIO    3 ROOM   331  ANG MO KIO AVE 1     07 TO 09\n4 2022    01 ANG MO KIO    3 ROOM   534 ANG MO KIO AVE 10     07 TO 09\n5 2022    01 ANG MO KIO    3 ROOM   578 ANG MO KIO AVE 10     04 TO 06\n6 2022    01 ANG MO KIO    3 ROOM   452 ANG MO KIO AVE 10     01 TO 03\n  floor_area_sqm     flat_model lease_commence_date years months resale_price\n1             73 New Generation                1977    54      5       358000\n2             67 New Generation                1978    55      1       355000\n3             68 New Generation                1981    58      0       338000\n4             82 New Generation                1980    57      2       420000\n5             67 New Generation                1980    57      1       328000\n6             83 New Generation                1979    56      7       360000\n  rem_lease_inmonths\n1                653\n2                661\n3                696\n4                686\n5                685\n6                679\n\n\n\n\nd) Deriving new variables\nThe code chunk below creates a new variable price per square feet (psf), which is commonly used to compare the price of houses of different sizes. I did this by dividing total resale price by floor area (converted from meters to feet by multiplying by 10.7639).\n\n\nCode\nresale_data_psf <- resale_data_order %>%\n  mutate(`psf` = as.integer(round(resale_price/(floor_area_sqm * 10.7639), 2)))\n\nhead(resale_data_psf)\n\n\n  year month       town flat_type block       street_name storey_range\n1 2022    01 ANG MO KIO    3 ROOM   320  ANG MO KIO AVE 1     07 TO 09\n2 2022    01 ANG MO KIO    3 ROOM   225  ANG MO KIO AVE 1     07 TO 09\n3 2022    01 ANG MO KIO    3 ROOM   331  ANG MO KIO AVE 1     07 TO 09\n4 2022    01 ANG MO KIO    3 ROOM   534 ANG MO KIO AVE 10     07 TO 09\n5 2022    01 ANG MO KIO    3 ROOM   578 ANG MO KIO AVE 10     04 TO 06\n6 2022    01 ANG MO KIO    3 ROOM   452 ANG MO KIO AVE 10     01 TO 03\n  floor_area_sqm     flat_model lease_commence_date years months resale_price\n1             73 New Generation                1977    54      5       358000\n2             67 New Generation                1978    55      1       355000\n3             68 New Generation                1981    58      0       338000\n4             82 New Generation                1980    57      2       420000\n5             67 New Generation                1980    57      1       328000\n6             83 New Generation                1979    56      7       360000\n  rem_lease_inmonths psf\n1                653 455\n2                661 492\n3                696 461\n4                686 475\n5                685 454\n6                679 402\n\n\n\n\ne) Re-coding variables\nThe code chunks below visualizes the town distribution.\n\n\nCode\nggplot(data = resale_data_psf,\n       aes(y = town)) +\n  geom_bar() +\n  theme_bw() +  \n  ggtitle(\"Town distribution\")\n\n\n\n\n\nThe code chunk below recodes the town variable into 3 market segments as defined by the Urban Redevelopment Authority (URA); Core Central Region (CCR), Rest of Central Region (RCR) and Outside Central Region (OCR).\n\n\nCode\nCCR <- c(\"CENTRAL AREA\", \"BUKIT TIMAH\")\nRCR <- c(\"TOA PAYOH\", \"QUEENSTOWN\", \"MARINE PARADE\", \"KALLANG/WHAMPOA\", \"GEYLANG\",\"BISHAN\")\nOCR <- c(\"YISHUN\", \"WOODLANDS\", \"TAMPINES\", \"SERANGOON\", \"SENGKANG\", \"SEMBAWANG\", \"PUNGGOL\", \"PASIR RIS\", \"JURONG WEST\", \"JURONG EAST\", \"HOUGANG\", \"CLEMENTI\", \"CHOA CHU KANG\", \"BUKIT PANJANG\", \"BUKIT MERAH\", \"BUKIT BATOK\", \"BEDOK\", \"ANG MO KIO\")\n\nresale_data_final <- resale_data_psf %>%\n  mutate(market_segment = recode(town, \n  \"CENTRAL AREA\" = \"Core Central Region\",\n  \"BUKIT TIMAH\" = \"Core Central Region\",\n  \"TOA PAYOH\" = \"Rest of Central Region\",\n  \"QUEENSTOWN\" = \"Rest of Central Region\",\n  \"MARINE PARADE\" = \"Rest of Central Region\",\n  \"KALLANG/WHAMPOA\" = \"Rest of Central Region\",\n  \"GEYLANG\" = \"Rest of Central Region\",\n  \"BISHAN\" = \"Rest of Central Region\",\n  \"YISHUN\" = \"Outside Central Region\",\n  \"WOODLANDS\" = \"Outside Central Region\",\n  \"TAMPINES\" = \"Outside Central Region\",\n  \"SERANGOON\" = \"Outside Central Region\",\n  \"SENGKANG\" = \"Outside Central Region\",\n  \"SEMBAWANG\" = \"Outside Central Region\",\n  \"PUNGGOL\" = \"Outside Central Region\",\n  \"PASIR RIS\" = \"Outside Central Region\",\n  \"JURONG WEST\" = \"Outside Central Region\",\n  \"JURONG EAST\" = \"Outside Central Region\",\n  \"HOUGANG\" = \"Outside Central Region\",\n  \"CLEMENTI\" = \"Outside Central Region\",\n  \"CHOA CHU KANG\" = \"Outside Central Region\",\n  \"BUKIT PANJANG\" = \"Outside Central Region\",\n  \"BUKIT MERAH\" = \"Outside Central Region\",\n  \"BUKIT BATOK\" = \"Outside Central Region\",\n  \"BEDOK\" = \"Outside Central Region\",\n  \"ANG MO KIO\" = \"Outside Central Region\"))\n  \nhead(resale_data_final)\n\n\n  year month       town flat_type block       street_name storey_range\n1 2022    01 ANG MO KIO    3 ROOM   320  ANG MO KIO AVE 1     07 TO 09\n2 2022    01 ANG MO KIO    3 ROOM   225  ANG MO KIO AVE 1     07 TO 09\n3 2022    01 ANG MO KIO    3 ROOM   331  ANG MO KIO AVE 1     07 TO 09\n4 2022    01 ANG MO KIO    3 ROOM   534 ANG MO KIO AVE 10     07 TO 09\n5 2022    01 ANG MO KIO    3 ROOM   578 ANG MO KIO AVE 10     04 TO 06\n6 2022    01 ANG MO KIO    3 ROOM   452 ANG MO KIO AVE 10     01 TO 03\n  floor_area_sqm     flat_model lease_commence_date years months resale_price\n1             73 New Generation                1977    54      5       358000\n2             67 New Generation                1978    55      1       355000\n3             68 New Generation                1981    58      0       338000\n4             82 New Generation                1980    57      2       420000\n5             67 New Generation                1980    57      1       328000\n6             83 New Generation                1979    56      7       360000\n  rem_lease_inmonths psf         market_segment\n1                653 455 Outside Central Region\n2                661 492 Outside Central Region\n3                696 461 Outside Central Region\n4                686 475 Outside Central Region\n5                685 454 Outside Central Region\n6                679 402 Outside Central Region\n\n\nThe code chunks below visualizes the storey range distribution.\n\n\nCode\nggplot(data = resale_data_psf,\n       aes(y = storey_range)) +\n  geom_bar() +\n  theme_bw() +  \n  ggtitle(\"Storey range distribution\")\n\n\n\n\n\nI initially thought of re-coding storey range into ‘low’, ‘middle’ and ‘high’ floor but found that this may not allow a fair comparison as different buildings have different number of storeys. It is difficult to have a standardized definition of ‘low’, ‘middle’ and ‘high’ floor. For some buildings, 10th storey may be considered a high floor, but for other buildings, 10th storey may be the middle floor.\n\n\nCode\nskimr::skim(resale_data_final)\n\n\n\nData summary\n\n\nName\nresale_data_final\n\n\nNumber of rows\n24374\n\n\nNumber of columns\n16\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n8\n\n\nfactor\n1\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nyear\n0\n1\n4\n4\n0\n1\n0\n\n\nmonth\n0\n1\n2\n2\n0\n12\n0\n\n\ntown\n0\n1\n5\n15\n0\n26\n0\n\n\nflat_type\n0\n1\n6\n6\n0\n3\n0\n\n\nblock\n0\n1\n1\n4\n0\n2457\n0\n\n\nstreet_name\n0\n1\n7\n20\n0\n552\n0\n\n\nflat_model\n0\n1\n4\n22\n0\n16\n0\n\n\nmarket_segment\n0\n1\n19\n22\n0\n3\n0\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nstorey_range\n0\n1\nFALSE\n17\n04 : 5453, 07 : 5110, 10 : 4499, 01 : 4118\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nfloor_area_sqm\n0\n1\n94.07\n19.32\n51\n81\n93\n110\n159\n▅▇▆▃▁\n\n\nlease_commence_date\n0\n1\n1997.46\n14.98\n1967\n1985\n1998\n2014\n2019\n▂▆▅▃▇\n\n\nyears\n0\n1\n74.06\n15.02\n43\n61\n74\n91\n96\n▂▇▃▅▇\n\n\nmonths\n0\n1\n5.56\n3.49\n0\n3\n6\n9\n11\n▇▅▅▅▇\n\n\nresale_price\n0\n1\n536391.17\n157993.72\n200000\n428000\n515000\n610000\n1418000\n▅▇▂▁▁\n\n\nrem_lease_inmonths\n0\n1\n894.28\n180.23\n517\n741\n895\n1097\n1157\n▂▇▅▅▇\n\n\npsf\n0\n1\n532.40\n126.65\n309\n449\n498\n573\n1368\n▇▅▁▁▁"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#visual-statistical-analysis",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#visual-statistical-analysis",
    "title": "Take-home Exercise 03",
    "section": "3.1 Visual Statistical Analysis",
    "text": "3.1 Visual Statistical Analysis\nIn this section, I attempt to understand the difference in means of prices between different market segments and flat type. To do so, I use the Oneway ANOVA tests, which will show the comparison between means. After which, I attempt to understand the correlation of remaining lease with price, first by using significant test of correlation followed by a multi-linear regression where I include control variables.\n\na) Oneway ANOVA Test: ggbetweenstats() method\nPrice By Market Segment\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on price per square feet (psf) by market segment. The purpose is to test if indeed the price per square feet differs significantly across the 3 market segments. The null hypothesis is that all population means are equal (i.e. no variation in means across the 3 market segments ) while the alternative hypothesis is that at least 1 population mean is different.\n\n\nCode\nggbetweenstats(\n  data = resale_data_final,\n  x = market_segment, \n  y = psf,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\nAnalysis:\nFrom the visualization, we can see that the p-value is extremely small (<0.01). This means that we reject the null hypothesis and say that there is evidence that not all the means are the same and at least 1 mean is different across the 3 market segments, statistically significant at 1% level.\nPrice By Flat Type\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on price per square feet (psf) by flat type (3, 4 & 5 Room). The purpose is to test if indeed the psf differs significantly across the flat types. The null hypothesis is that all population means are equal (i.e. no variation in means across the 3 market segments) while the alternative hypothesis is that at least 1 population mean is different.\n\n\nCode\nggbetweenstats(\n  data = resale_data_final,\n  x = flat_type, \n  y = psf,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\nAnalysis:\nFrom the visualization, we can see that the p-value is extremely small (<0.01). This means that we reject the null hypothesis and say that there is evidence that not all the means are the same and at least 1 mean is different across the 3 flat types, statistically significant at 1% level.\nWe can also see that 4 ROOM flat type has highest mean psf, followed by 3 ROOM then 5 ROOM. It is interesting that 4 ROOM mean psf is actually higher than that of 3 ROOM since we usually expect that the bigger the flat, the lower the psf.\n\n\nb) Significant Test of Correlation: ggscatterstats()\nIn the code chunks below, ggscatterstats() is used to build a visual for Significant Test of Correlation between remaining lease in months and resale price per sf (psf).\n\n\nCode\nggscatterstats(\n  data = resale_data_final,\n  x = psf,\n  y = rem_lease_inmonths,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\nCode\nggscatterstats(\n  data = resale_data_final,\n  x = rem_lease_inmonths,\n  y = psf,\n  marginal = FALSE,\n  )\n\n\n\n\n\nAnalysis:\nThere seems to be a statistically significant positive correlation between psf and remaining lease. The higher the remaining lease, the higher the price per square feet. To further support this, we want to include some control variables by having a multi-linear regression model including control variables such as flat type, flat model, market segment and month as shown below.\n\n\nc) Multiple Regression Model using lm()\nThe code chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of . The dependent/Y variable is psf while the independent/X variables are remaining lease, flat type, flat model, market segment and month.\n\n\nCode\nmodel <- lm(psf ~ rem_lease_inmonths + flat_type + flat_model + market_segment + month, data = resale_data_final)\n\nmodel\n\n\n\nCall:\nlm(formula = psf ~ rem_lease_inmonths + flat_type + flat_model + \n    market_segment + month, data = resale_data_final)\n\nCoefficients:\n                         (Intercept)                    rem_lease_inmonths  \n                            264.0395                                0.4587  \n                     flat_type4 ROOM                       flat_type5 ROOM  \n                            -30.6890                              -37.4823  \n             flat_modelAdjoined flat                        flat_modelDBSS  \n                             96.5466                              217.7092  \n                  flat_modelImproved         flat_modelImproved-Maisonette  \n                             40.8898                              162.1900  \n                   flat_modelModel A          flat_modelModel A-Maisonette  \n                             42.0292                              129.2770  \n                  flat_modelModel A2              flat_modelNew Generation  \n                             11.5564                               91.7886  \n         flat_modelPremium Apartment      flat_modelPremium Apartment Loft  \n                             40.3449                              239.3396  \n                flat_modelSimplified                    flat_modelStandard  \n                             74.9831                               84.1695  \n                   flat_modelTerrace                     flat_modelType S1  \n                            353.6917                              329.4812  \n                   flat_modelType S2  market_segmentOutside Central Region  \n                            335.9461                             -223.5458  \nmarket_segmentRest of Central Region                               month02  \n                            -56.2748                                5.6644  \n                             month03                               month04  \n                             10.3838                               17.0764  \n                             month05                               month06  \n                             21.1960                               27.2774  \n                             month07                               month08  \n                             28.6735                               30.4727  \n                             month09                               month10  \n                             36.1532                               41.7470  \n                             month11                               month12  \n                             37.6914                               39.9656  \n\n\n\n\nCode\nggcoefstats(model, \n            output = \"plot\")\n\n\n\n\n\n\n\nCode\ncheck_collinearity(model)\n\n\n# Check for Multicollinearity\n\nLow Correlation\n\n               Term  VIF   VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n rem_lease_inmonths 2.01 [1.97, 2.05]         1.42      0.50     [0.49, 0.51]\n          flat_type 2.75 [2.69, 2.81]         1.66      0.36     [0.36, 0.37]\n              month 1.01 [1.00, 1.04]         1.01      0.99     [0.97, 1.00]\n         flat_model 6.18 [6.04, 6.33]         2.49      0.16     [0.16, 0.17]\n\nModerate Correlation\n\n           Term  VIF   VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n market_segment 1.62 [1.59, 1.65]         1.27      0.62     [0.61, 0.63]\n\n\n\n\nCode\ncheck_c <- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\n\n\nCode\ncheck_n <- check_normality(model)\n\nplot(check_n)\n\n\n\n\n\n\n\nCode\ncheck_h <- check_heteroscedasticity(model)\n\nplot(check_h)\n\n\n\n\n\n\n\nCode\ncheck_model(model)\n\n\n\n\n\nAnalysis:\nAfter controlling for several variables (i.e. holding them constant), we see that remaining lease still has a statistically significantly positive correlation with price per sf, similar to the findings we found in sub-section b above. In this regression model, we see that for every 1 month increase in remaining lease, psf increases by $0.46.\nThere doesn’t seem to be multi-collinearity as we can see that the VIFs are <10. The distribution also seems somewhat normal although heteroscedasticity may not hold true."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#visualizing-uncertainty",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#visualizing-uncertainty",
    "title": "Take-home Exercise 03",
    "section": "3.2 Visualizing Uncertainty",
    "text": "3.2 Visualizing Uncertainty\nIn this section, I attempt to visualize uncertainty using standard error of mean of price per sf by flat type. This will enable me to compare the uncertainty of the point estimate.\n\n\nCode\nmy_sum <- resale_data_final %>%\n  group_by(flat_type) %>%\n  summarise(\n    n=n(),\n    mean=mean(psf),\n    sd=sd(psf)\n    ) %>%\n  mutate(se=sd/sqrt(n-1))\n\n\n\n\nCode\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n\n \n  \n    flat_type \n    n \n    mean \n    sd \n    se \n  \n \n\n  \n    3 ROOM \n    6346 \n    531.9578 \n    114.2673 \n    1.434518 \n  \n  \n    4 ROOM \n    11312 \n    540.8934 \n    136.1932 \n    1.280575 \n  \n  \n    5 ROOM \n    6716 \n    518.5222 \n    119.7026 \n    1.460766 \n  \n\n\n\n\n\n\n\nCode\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(flat_type, -mean),\n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=flat_type, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean \n          psf by flat type\")\n\n\n\n\n\n\n\nCode\nresale_data_final %>%\n  ggplot(aes(x = flat_type, \n             y = psf)) +\n  stat_pointinterval(\n    show.legend = FALSE) +   \n  labs(\n    title = \"Visualising confidence intervals of mean psf\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\nCode\ndevtools::install_github(\"wilkelab/ungeviz\")\n\n\n\n\nCode\nlibrary(ungeviz)\n\n\n\n\nCode\nggplot(data = resale_data_final, \n       (aes(x = factor(flat_type), y = psf))) +\n  geom_point(position = position_jitter(\n    height = 0.3, width = 0.05), \n    size = 0.4, color = \"#0072B2\", alpha = 1/2) +\n  geom_hpline(data = sampler(25, group = flat_type), height = 0.6, color = \"#D55E00\") +\n  theme_bw() + \n  # `.draw` is a generated column indicating the sample draw\n  transition_states(.draw, 1, 3)\n\n\n\n\n\nAnalysis:\nIt appears that the Standard Error seems to be very similar between the different flat types. The error bars are about the same height. This shows that the uncertainty of the means are very similar across the flat types and they can be compared.\nThe confidence intervals seems to overlap between the 3 flat types, which could mean that the mean psf may not be statistically significantly different from each other. However, from the one way ANOVA test in section 3.1, we saw that they are statistically significantly different."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html",
    "title": "Take-home Exercise 4",
    "section": "",
    "text": "In this take-home exercise, I will uncover the impact of COVID-19 as well as the global economic and political dynamic in 2022 on Singapore’s bi-lateral trade (i.e. Import, Export and Trade Balance) by using appropriate analytical visualisation techniques learned in Lesson 6: It’s About Time.\nMerchandise Trade provided by Department of Statistics, Singapore (DOS) will be used to prepare the analytical visualisation and processed by RStudio tidyverse family of packages and visualized by ggplot2 and its extensions as well as other R packages. The study period will be between January 2020 to December 2022."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#installing-and-launching-r-packages",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#installing-and-launching-r-packages",
    "title": "Take-home Exercise 4",
    "section": "2.1 Installing and launching R packages",
    "text": "2.1 Installing and launching R packages\nThe code chunk below uses p_load() of pacman package to check if the various packages used for the visual analysis are installed in the computer. If they are, then they will be launched into R.\n\n\nCode\npacman::p_load(ggstatsplot, tidyverse, readxl, performance, parameters, see, plotly, crosstalk, DT, ggdist, gganimate, gifski, gapminder, scales, viridis, lubridate, ggthemes, gridExtra, tidyverse, readxl, knitr, data.table, ggpubr, tidyr, CGPfunctions,  ggHoriPlot, remotes)\n\nremotes::install_github(\"nsgrantham/ggbraid\")\n\n#library(plotly)\nlibrary(ggbraid)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#importing-the-data",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#importing-the-data",
    "title": "Take-home Exercise 4",
    "section": "2.2 Importing the data",
    "text": "2.2 Importing the data\nThe code chunk below imports merchandisetrade.xlsx from the data folder into R by using read_excel() of readr and save it as 2 tibble data frames called import_data1 and export_data1.\nIt also filters for January 2020 to December 2022 data.\n\n\nCode\nimport_data1 <- read_excel(\"data/merchandisetrade.xlsx\",\n                           sheet = \"T2\",\n                           range = cell_rows(10:129)) %>%\n  select(`Data Series`, contains(c(\"2020\", \"2021\", \"2022\"))) %>%\n  slice(-1)\n  \nhead(import_data1)\n\n\n# A tibble: 6 × 37\n  `Data Series`  2020 …¹ 2020 …² 2020 …³ 2020 …⁴ 2020 …⁵ 2020 …⁶ 2020 …⁷ 2020 …⁸\n  <chr>            <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 America (Mill…   4676.   4588.   4870.   4886.   4132    4667.   4686.   4259 \n2 Asia (Million…  28200.  25845.  26128.  27823.  26052.  26767.  24779.  21719.\n3 Europe (Milli…   6087.   6134.   6285.   5317.   5225    5475.   4961.   4629 \n4 Oceania (Mill…    541.   1413.    577.    478.    586.    493.    456.    442.\n5 Africa (Milli…    649.    499.    314.    297.    476.    441.    238.    410.\n6 European Unio…   4251.   4373.   4632.   3766.   3345.   3736.   3423.   2910.\n# … with 28 more variables: `2020 Apr` <dbl>, `2020 Mar` <dbl>,\n#   `2020 Feb` <dbl>, `2020 Jan` <dbl>, `2021 Dec` <dbl>, `2021 Nov` <dbl>,\n#   `2021 Oct` <dbl>, `2021 Sep` <dbl>, `2021 Aug` <dbl>, `2021 Jul` <dbl>,\n#   `2021 Jun` <dbl>, `2021 May` <dbl>, `2021 Apr` <dbl>, `2021 Mar` <dbl>,\n#   `2021 Feb` <dbl>, `2021 Jan` <dbl>, `2022 Dec` <dbl>, `2022 Nov` <dbl>,\n#   `2022 Oct` <dbl>, `2022 Sep` <dbl>, `2022 Aug` <dbl>, `2022 Jul` <dbl>,\n#   `2022 Jun` <dbl>, `2022 May` <dbl>, `2022 Apr` <dbl>, `2022 Mar` <dbl>, …\n\n\n\n\nCode\nexport_data1 <-  read_xlsx(\"data/merchandisetrade.xlsx\",\n                          sheet = \"T1\",\n                          range = cell_rows(10:101)) %>% \n  select(`Data Series`, contains(c(\"2020\", \"2021\", \"2022\"))) %>%\n  slice(-1)\n\nhead(export_data1)\n\n\n# A tibble: 6 × 37\n  `Data Series`  2020 …¹ 2020 …² 2020 …³ 2020 …⁴ 2020 …⁵ 2020 …⁶ 2020 …⁷ 2020 …⁸\n  <chr>            <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 America (Mill…   5654.   5402.   5099.   4796.   5164.   6884.   4896.   5922.\n2 Asia (Million…  34688.  32143.  32141.  31782.  31658.  29809.  28994.  24438.\n3 Europe (Milli…   3786.   3594.   4757.   5117.   5178.   4014.   4880.   4398 \n4 Oceania (Mill…   1656.   1649.   1581    1640.   1811.   1726.   1418.   1311.\n5 Africa (Milli…    464.    504.    510.    572.    522.    461.    452.    413.\n6 European Unio…   3190.   2991.   3789.   4061    3613.   3198.   3424.   3854.\n# … with 28 more variables: `2020 Apr` <dbl>, `2020 Mar` <dbl>,\n#   `2020 Feb` <dbl>, `2020 Jan` <dbl>, `2021 Dec` <dbl>, `2021 Nov` <dbl>,\n#   `2021 Oct` <dbl>, `2021 Sep` <dbl>, `2021 Aug` <dbl>, `2021 Jul` <dbl>,\n#   `2021 Jun` <dbl>, `2021 May` <dbl>, `2021 Apr` <dbl>, `2021 Mar` <dbl>,\n#   `2021 Feb` <dbl>, `2021 Jan` <dbl>, `2022 Dec` <dbl>, `2022 Nov` <dbl>,\n#   `2022 Oct` <dbl>, `2022 Sep` <dbl>, `2022 Aug` <dbl>, `2022 Jul` <dbl>,\n#   `2022 Jun` <dbl>, `2022 May` <dbl>, `2022 Apr` <dbl>, `2022 Mar` <dbl>, …"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#data-wrangling",
    "title": "Take-home Exercise 4",
    "section": "2.3 Data wrangling",
    "text": "2.3 Data wrangling\n\na) Explore the data\n\n\nCode\nhead(skimr::skim(import_data1))\n\n\n\nData summary\n\n\nName\nimport_data1\n\n\nNumber of rows\n118\n\n\nNumber of columns\n37\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nData Series\n0\n1\n22\n53\n0\n118\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\n2020 Dec\n0\n1\n333250.8\n974409.3\n0\n169.75\n7174.00\n130818.5\n6202327\n▇▁▁▁▁\n\n\n2020 Nov\n0\n1\n319340.5\n938043.2\n0\n116.75\n5735.25\n133326.2\n6280686\n▇▁▁▁▁\n\n\n2020 Oct\n0\n1\n317425.3\n925927.0\n0\n80.50\n5345.50\n124435.8\n5249328\n▇▁▁▁▁\n\n\n2020 Sep\n0\n1\n324791.5\n925020.3\n0\n122.50\n7756.00\n93170.5\n5479579\n▇▁▁▁▁\n\n\n2020 Aug\n0\n1\n303788.9\n885364.5\n0\n144.25\n6057.50\n95664.0\n5574117\n▇▁▁▁▁\n\n\n\n\n\n\n\nCode\nhead(skimr::skim(export_data1))\n\n\n\nData summary\n\n\nName\nexport_data1\n\n\nNumber of rows\n90\n\n\nNumber of columns\n37\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nData Series\n0\n1\n22\n52\n0\n90\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\n2020 Dec\n0\n1\n500637.4\n1244184\n0\n6825.50\n35537.90\n219175.2\n7090834\n▇▁▁▁▁\n\n\n2020 Nov\n0\n1\n468219.2\n1169363\n0\n6485.75\n36915.00\n244342.5\n6852887\n▇▁▁▁▁\n\n\n2020 Oct\n0\n1\n476473.3\n1169380\n0\n5673.25\n35167.45\n255064.2\n6992713\n▇▁▁▁▁\n\n\n2020 Sep\n0\n1\n473427.6\n1141417\n0\n5206.77\n34522.15\n249263.5\n6561515\n▇▁▁▁▁\n\n\n2020 Aug\n0\n1\n475320.8\n1194167\n0\n5240.23\n31650.25\n243462.5\n7970167\n▇▁▁▁▁\n\n\n\n\n\n\n\nb) Change data series column into 2 columns: country and unit\nImport data\n\n\nCode\nimport_data <- import_data1 %>%\n  separate(`Data Series`, c(\"country\", \"unit\"),\n           sep = ' \\\\(') %>%\n  mutate(unit = str_remove(unit, '\\\\)'))\n\nhead(import_data)\n\n\n# A tibble: 6 × 38\n  country  unit  2020 …¹ 2020 …² 2020 …³ 2020 …⁴ 2020 …⁵ 2020 …⁶ 2020 …⁷ 2020 …⁸\n  <chr>    <chr>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 America  Mill…   4676.   4588.   4870.   4886.   4132    4667.   4686.   4259 \n2 Asia     Mill…  28200.  25845.  26128.  27823.  26052.  26767.  24779.  21719.\n3 Europe   Mill…   6087.   6134.   6285.   5317.   5225    5475.   4961.   4629 \n4 Oceania  Mill…    541.   1413.    577.    478.    586.    493.    456.    442.\n5 Africa   Mill…    649.    499.    314.    297.    476.    441.    238.    410.\n6 Europea… Mill…   4251.   4373.   4632.   3766.   3345.   3736.   3423.   2910.\n# … with 28 more variables: `2020 Apr` <dbl>, `2020 Mar` <dbl>,\n#   `2020 Feb` <dbl>, `2020 Jan` <dbl>, `2021 Dec` <dbl>, `2021 Nov` <dbl>,\n#   `2021 Oct` <dbl>, `2021 Sep` <dbl>, `2021 Aug` <dbl>, `2021 Jul` <dbl>,\n#   `2021 Jun` <dbl>, `2021 May` <dbl>, `2021 Apr` <dbl>, `2021 Mar` <dbl>,\n#   `2021 Feb` <dbl>, `2021 Jan` <dbl>, `2022 Dec` <dbl>, `2022 Nov` <dbl>,\n#   `2022 Oct` <dbl>, `2022 Sep` <dbl>, `2022 Aug` <dbl>, `2022 Jul` <dbl>,\n#   `2022 Jun` <dbl>, `2022 May` <dbl>, `2022 Apr` <dbl>, `2022 Mar` <dbl>, …\n\n\nExport data\n\n\nCode\nexport_data <- export_data1 %>%\n  separate(`Data Series`, c(\"country\", \"unit\"),\n           sep = ' \\\\(') %>%\n  mutate(unit = str_remove(unit, '\\\\)'))\n\nhead(export_data)\n\n\n# A tibble: 6 × 38\n  country  unit  2020 …¹ 2020 …² 2020 …³ 2020 …⁴ 2020 …⁵ 2020 …⁶ 2020 …⁷ 2020 …⁸\n  <chr>    <chr>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 America  Mill…   5654.   5402.   5099.   4796.   5164.   6884.   4896.   5922.\n2 Asia     Mill…  34688.  32143.  32141.  31782.  31658.  29809.  28994.  24438.\n3 Europe   Mill…   3786.   3594.   4757.   5117.   5178.   4014.   4880.   4398 \n4 Oceania  Mill…   1656.   1649.   1581    1640.   1811.   1726.   1418.   1311.\n5 Africa   Mill…    464.    504.    510.    572.    522.    461.    452.    413.\n6 Europea… Mill…   3190.   2991.   3789.   4061    3613.   3198.   3424.   3854.\n# … with 28 more variables: `2020 Apr` <dbl>, `2020 Mar` <dbl>,\n#   `2020 Feb` <dbl>, `2020 Jan` <dbl>, `2021 Dec` <dbl>, `2021 Nov` <dbl>,\n#   `2021 Oct` <dbl>, `2021 Sep` <dbl>, `2021 Aug` <dbl>, `2021 Jul` <dbl>,\n#   `2021 Jun` <dbl>, `2021 May` <dbl>, `2021 Apr` <dbl>, `2021 Mar` <dbl>,\n#   `2021 Feb` <dbl>, `2021 Jan` <dbl>, `2022 Dec` <dbl>, `2022 Nov` <dbl>,\n#   `2022 Oct` <dbl>, `2022 Sep` <dbl>, `2022 Aug` <dbl>, `2022 Jul` <dbl>,\n#   `2022 Jun` <dbl>, `2022 May` <dbl>, `2022 Apr` <dbl>, `2022 Mar` <dbl>, …\n\n\n\n\nc) Split tables\nThe table has data for each region (unit in ‘Millions’) and for each country (unit in ’Thousands). We will split them into separate tables so that we can analyse them cleanly. We should compare regions with other regions and countries with other countries.\nImport by Region\n\n\nCode\nimport_region <- import_data %>%\n  filter(str_detect(unit, \"Million\")) %>%\n  select(-(unit))\n\n\nExport by Region\n\n\nCode\nexport_region <- export_data %>%\n  filter(str_detect(unit, \"Million\")) %>%\n  select(-(unit))\n\n\nImport by Country\n\n\nCode\nimport_country <- import_data %>%\n  filter(str_detect(unit, \"Thousand\")) %>%\n  select(-(unit))\n\n\nExport by Country\n\n\nCode\nexport_country <- export_data %>%\n  filter(str_detect(unit, \"Thousand\")) %>%\n  select(-(unit))\n\n\n\n\nd) Create trade balance variable (Value of Exports − Value of Imports)\n\ni. Pivot import data from wide to long\n\n\nCode\nimport_pivot_country <- import_country %>%\n  pivot_longer(cols = !country,\n               names_to = \"temporary\",\n               values_to = \"import\") %>%\n  mutate(period = (lubridate::ym(temporary))) %>%\n  arrange(country, period) %>%\n  select(-temporary) %>%\n  relocate(period)\n\nhead(import_pivot_country)\n\n\n# A tibble: 6 × 3\n  period     country     import\n  <date>     <chr>        <dbl>\n1 2020-01-01 Afghanistan      7\n2 2020-02-01 Afghanistan     66\n3 2020-03-01 Afghanistan      6\n4 2020-04-01 Afghanistan     16\n5 2020-05-01 Afghanistan     15\n6 2020-06-01 Afghanistan     72\n\n\n\n\nCode\nimport_pivot_region <- import_region %>%\n  pivot_longer(cols = !country,\n               names_to = \"temporary\",\n               values_to = \"import\") %>%\n  mutate(period = (lubridate::ym(temporary))) %>%\n  arrange(country, period) %>%\n  select(-temporary) %>%\n  relocate(period)\n\nhead(import_pivot_region)\n\n\n# A tibble: 6 × 3\n  period     country import\n  <date>     <chr>    <dbl>\n1 2020-01-01 Africa    529.\n2 2020-02-01 Africa    666.\n3 2020-03-01 Africa    559.\n4 2020-04-01 Africa    373.\n5 2020-05-01 Africa    410.\n6 2020-06-01 Africa    238.\n\n\n\n\nii. Pivot export data from wide to long\n\n\nCode\nexport_pivot_country <- export_country %>%\n  pivot_longer(cols = !country,\n               names_to = 'temporary',\n               values_to = \"export\") %>%\n  mutate(period = (lubridate::ym(temporary))) %>%\n  arrange(country, period) %>%\n  select(-temporary) %>%\n  relocate(period)\n\nhead(export_pivot_country)\n\n\n# A tibble: 6 × 3\n  period     country     export\n  <date>     <chr>        <dbl>\n1 2020-01-01 Afghanistan   3606\n2 2020-02-01 Afghanistan   2199\n3 2020-03-01 Afghanistan   5293\n4 2020-04-01 Afghanistan   1771\n5 2020-05-01 Afghanistan   3709\n6 2020-06-01 Afghanistan   1752\n\n\n\n\nCode\nexport_pivot_region <- export_region %>%\n  pivot_longer(cols = !country,\n               names_to = 'temporary',\n               values_to = \"export\") %>%\n  mutate(period = (lubridate::ym(temporary))) %>%\n  arrange(country, period) %>%\n  select(-temporary) %>%\n  relocate(period)\n\nhead(export_pivot_region)\n\n\n# A tibble: 6 × 3\n  period     country export\n  <date>     <chr>    <dbl>\n1 2020-01-01 Africa    722.\n2 2020-02-01 Africa    841 \n3 2020-03-01 Africa    916.\n4 2020-04-01 Africa    569.\n5 2020-05-01 Africa    413.\n6 2020-06-01 Africa    452.\n\n\n\n\niii. Join the 2 pivoted tables\n\n\nCode\ntrade_balance_country <- import_pivot_country %>% full_join(export_pivot_country)\n\n\n\n\nCode\ntrade_balance_region <- import_pivot_region %>% full_join(export_pivot_region)\n\n\n\n\niv. Create variable\n\n\nCode\ntrade_balance_country <- trade_balance_country %>%\n  mutate(tradebalance = export-import) \n\nhead(trade_balance_country)\n\n\n# A tibble: 6 × 5\n  period     country     import export tradebalance\n  <date>     <chr>        <dbl>  <dbl>        <dbl>\n1 2020-01-01 Afghanistan      7   3606         3599\n2 2020-02-01 Afghanistan     66   2199         2133\n3 2020-03-01 Afghanistan      6   5293         5287\n4 2020-04-01 Afghanistan     16   1771         1755\n5 2020-05-01 Afghanistan     15   3709         3694\n6 2020-06-01 Afghanistan     72   1752         1680\n\n\n\n\nCode\ntrade_balance_region <- trade_balance_region %>%\n  mutate(tradebalance = export-import) %>%\n  rename(country, region = country) \n\nhead(trade_balance_region)\n\n\n# A tibble: 6 × 5\n  period     region import export tradebalance\n  <date>     <chr>   <dbl>  <dbl>        <dbl>\n1 2020-01-01 Africa   529.   722.       193.  \n2 2020-02-01 Africa   666.   841        175.  \n3 2020-03-01 Africa   559.   916.       357.  \n4 2020-04-01 Africa   373.   569.       196.  \n5 2020-05-01 Africa   410.   413.         3.20\n6 2020-06-01 Africa   238.   452.       214."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#cycle-plot",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#cycle-plot",
    "title": "Take-home Exercise 4",
    "section": "3.1 Cycle Plot",
    "text": "3.1 Cycle Plot\nWe will create the cycle plot to visualise the trends between 2020 to 2022 for each month for Mainland China, United States, Malaysia which are Singapore’s top 3 trading partners.\nStep 1: Deriving month and year fields\n\n\nCode\ntrade_balance_country$month <- factor(month(trade_balance_country$`period`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \ntrade_balance_country$year <- year(ymd(trade_balance_country$`period`))\n\n\n\n\nCode\ntrade_balance_region$month <- factor(month(trade_balance_region$`period`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \ntrade_balance_region$year <- year(ymd(trade_balance_region$`period`))\n\n\nStep 2: Extracting the target country\n\n\nCode\nchina <- trade_balance_country %>% \n  filter(`country` == \"Mainland China\") %>%\n  select(`tradebalance`,\n         `country`,\n         `import`,\n         `export`,\n         month, \n         year)\n\n\n\n\nCode\nunitedstates <- trade_balance_country %>% \n  filter(`country` == \"United States\") %>%\n  select(`tradebalance`,\n         `country`,\n         `import`,\n         `export`,\n         month, \n         year)\n\n\n\n\nCode\nmalaysia <- trade_balance_country %>% \n  filter(`country` == \"Malaysia\") %>%\n  select(`tradebalance`,\n         `country`,\n         `import`,\n         `export`,\n         month, \n         year)\n\n\nStep 3: Computing year average trade balance by month\n\n\nCode\nhline.data.china <- china %>% \n  group_by(month) %>%\n  summarise(avgtradebalance = mean(`tradebalance`))\n\n\n\n\nCode\nhline.data.us <- unitedstates %>% \n  group_by(month) %>%\n  summarise(avgtradebalance = mean(`tradebalance`))\n\n\n\n\nCode\nhline.data.msia <- malaysia %>% \n  group_by(month) %>%\n  summarise(avgtradebalance = mean(`tradebalance`))\n\n\nStep 4: Plotting the cycle plot\ni) Mainland China:\n\n\nCode\nc <- ggplot() + \n  geom_line(data=china,\n            aes(x=year, \n                y=`tradebalance`, \n                group=month), \n            colour=\"black\") +\n  geom_line(data=china,\n            aes(x=year, \n                y=`import`, \n                group=month), \n            colour=\"orange\") +\n  geom_line(data=china,\n            aes(x=year, \n                y=`export`, \n                group=month), \n            colour=\"blue\") +\n  geom_hline(aes(yintercept=avgtradebalance), \n             data=hline.data.china, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n  title = \"Singapore' Trade Balance with China, Jan 2020-Dec 2022\") +\n  xlab(\"Year-over-year Performance\") +\n  ylab(\"Trade Balance (Thousand dollars)\") + \n  theme(axis.text.x = element_text(angle = 90))\n\nggplotly(c)\n\n\n\n\n\n\nAnalysis:\nJanuary to March:\nSingapore’s trade balance with China changed from negative (trade deficit) to positive (trade surplus) from 2020 to 2021 and increased from 2021 to 2022. We can see that this is because exports to China increased.\nApril to December:\nThere is an inverted V shape. Singapore’s trade balance with China improved from 2020 to 2021 but dropped from 2021 to 2022. This is because exports increased between 2020 to 2021 but dropped from 2021 to 2022. Meanwhile, imports increased from 2021 to 2022 for the months of May to November. Singapore’s increase in imports from China in that period is consistent with the increase in exports of China in that period as reported due to China’s economy opening up.\nWe are unable to see the typical steady state monthly trends that could possibly be seen in earlier years because of the extraordinary circumstances and geopolitical events between 2021 to 2022.\nii) United States\n\n\nCode\nus <- ggplot() + \n  geom_line(data=unitedstates,\n            aes(x=year, \n                y=`tradebalance`, \n                group=month), \n            colour=\"black\") +\n  geom_line(data=unitedstates,\n            aes(x=year, \n                y=`import`, \n                group=month), \n            colour=\"orange\") +\n  geom_line(data=unitedstates,\n            aes(x=year, \n                y=`export`, \n                group=month), \n            colour=\"blue\") +\n  geom_hline(aes(yintercept=avgtradebalance), \n             data=hline.data.us, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Singapore's Trade Balance with United States, Jan 2020-Dec 2022\") +\n  xlab(\"Year-over-year Performance\") +\n  ylab(\"Trade Balance (Thousand dollars)\") + \n  theme(axis.text.x = element_text(angle = 90))\n\nggplotly(us)\n\n\n\n\n\n\nAnalysis:\nSingapore’s trade balance with the United States changed from positive (trade surplus) to negative (trade deficit) to from 2020 to 2022 for most months except for January and March.\nSingapore could have had a trade surplus with the United States in 2020 because Singapore imported less in general due to the onset of Covid19. We see that from 2021 onwards, imports from United States generally shot up. The trend of having a trade deficit with United States from April to December in 2022 seems to be consistent with the trend with China. Singapore seems to be importing much more from both countries from April to December 2022 compared to the years before.\niii) Malaysia\n\n\nCode\nm <- ggplot() + \n  geom_line(data=malaysia,\n            aes(x=year, \n                y=`tradebalance`, \n                group=month), \n            colour=\"black\") +\n  geom_line(data=malaysia,\n            aes(x=year, \n                y=`import`, \n                group=month), \n            colour=\"orange\") +\n  geom_line(data=malaysia,\n            aes(x=year, \n                y=`export`, \n                group=month), \n            colour=\"blue\") +\n  geom_hline(aes(yintercept=avgtradebalance), \n             data=hline.data.msia, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Singapore's Trade Balance with Malaysia, Jan 2020-Dec 2022\") +\n  xlab(\"Year-over-year Performance\") +\n  ylab(\"Trade Balance (Thousand dollars)\") + \n  theme(axis.text.x = element_text(angle = 90))\n\nggplotly(m)\n\n\n\n\n\n\nAnalysis:\nSingapore’s trade balance with Malaysia seemed to have improved (reduction of trade deficit) for most months between 2021 to 2022 except for January, March, September and November. From the imports and exports we can see that both have generally increased between 2020 to 2022 for all months, although exports increase at a slightly faster rate due to increase in shipments of oil as reported."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#braid-chart",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#braid-chart",
    "title": "Take-home Exercise 4",
    "section": "3.2 Braid chart",
    "text": "3.2 Braid chart\nWe will create the slope graph to visualise how trade balance has changed between trade surplus and trade deficit between January 2020 to December 2022.\ni) By Region\nThe code chunk below creates the Braid chart to visualise how trade balance has changed between 2020 to 2022 for each of regions.\n\n\nCode\nggplot() +\n  geom_line(aes(period, import, linetype = region), data = trade_balance_region) +\n  geom_braid(aes(period, ymin = import, ymax = export, fill = import < export), data = trade_balance_region, alpha = 0.6) +\n  guides(linetype = \"none\", fill = \"none\") +\n  labs(axis.text.x = element_blank(),\n       title = \"Singapore's Trade Balance, 2020-2022\",\n       subtitle = \"Monthly Merchandise Export and Import Trade value with each region\",\n       caption = \"Note: The shaded blue area represents a higher export over import value, indicating a trade surplus.\\n The shaded red area represents a higher import over export value, indicating a trade deficit.\") +\n  xlab(\"Period\") +\n  ylab(\"Trade Balance (Million dollars)\") +\n  facet_grid(~ region) + \n  theme(axis.text.x = element_text(angle = 45))\n\n\n\n\n\nAnalysis:\nFrom the braid chart, we can see that Singapore has maintained mostly a trade surplus with Africa, Asia and Oceania except for some months. Similarly, Singapore has maintained mostly a trade deficit with Europe and European Union except for some months. In terms of trade balance with America, Singapore started off with mostly a trade surplus in 2020 but fluctuated between trade surplus and deficit in 2021 before having mostly a trade deficit in 2022.\nii) By Major Trading Partner\n\n\nCode\ntrade_balance_country_braid <- trade_balance_country %>%\n  filter(country %in% c(\"United States\", \"Japan\", \"Mainland China\", \"Hong Kong\", \"Malaysia\", \"Taiwan\", \"Republic Of Korea\", \"Thailand\", \"Indonesia\")) %>%\n  mutate(import = import/1000) %>%\n  mutate(export = export/1000)\n\n\nThe code chunk below creates the slope graph to visualise how trade balance has changed between 2020 to 2022 for each of Singapore’s major trading partner in terms of merchandise trade in 2022 based on Singstat.\n\n\nCode\nggplot() +\n  geom_line(aes(period, import, linetype = country), data = trade_balance_country_braid) +\n  geom_braid(aes(period, ymin = import, ymax = export, fill = import < export), data = trade_balance_country_braid, alpha = 0.6) +\n  guides(linetype = \"none\", fill = \"none\") +\n  labs(axis.text.x = element_blank(),\n       title = \"Singapore's Trade Balance, 2020-2022\",\n       subtitle = \"Monthly Merchandise Export and Import Trade value with Major Trading Partners\",\n       caption = \"Note: The shaded blue area represents a higher export over import value, indicating a trade surplus.\\n The shaded red area represents a higher import over export value, indicating a trade deficit.\") +\n  xlab(\"Period\") +\n  ylab(\"Trade Balance (Million dollars)\") +\n  facet_wrap(~ country) + \n  theme(axis.text.x = element_text(angle = 45))\n\n\n\n\n\nAnalysis:\nFrom the braid chart, we can see that Singapore has consistently maintained a trade surplus with Hong Kong and Indonesia as well as a trade deficit with Taiwan throughout 2020 to 2022. It has maintained mostly a trade surplus with Thailand and mostly a trade deficit with Malaysia except for certain months. Meanwhile, trade balance fluctuated for Mainland China and United States. For Japan and Republic of Korea, trade fluctuated in 2020 to 2021 but became mostly a trade deficit in 2022."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#slope-graph",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#slope-graph",
    "title": "Take-home Exercise 4",
    "section": "3.3 Slope Graph",
    "text": "3.3 Slope Graph\nWe will create the slope graph to visualise how trade balance has changed between 2020 to 2022.\ni) By Region\nThe code chunk below creates the slope graph to visualise how trade balance has changed between 2020 to 2022 for each of regions.\n\n\nCode\ntrade_balance_region %>% \n  mutate(year = factor(year)) %>%\n  filter(year %in% c(2020, 2022)) %>%\n  group_by(region, year) %>%\n  summarise(avgtradebalance = round(mean(`tradebalance`),2)) %>%\n  newggslopegraph(year, avgtradebalance, region,\n                Title = \"Singapore's Trade Balance with each region ($ million)\",\n                SubTitle = \"2020-2022\",\n                Caption = \"\")\n\n\n\n\n\nAnalysis:\nFrom the slope graph, we can see that Singapore’s trade balance worsened for Asia, America, European Union and Europe, but improved for Oceania and Africa between 2020 and 2022. America which ranked 3 in terms of trade surplus in 2020 became the second highest region in terms of trade deficit in 2022. Meanwhile, both Africa and the European Union over took America in terms of improvement of trade balance. The trade surplus with Africa became higher although trade deficit with European Union worsened slightly.\nii) By Major Trading Partner\nThe code chunk below creates the slope graph to visualise how trade balance has changed between 2020 to 2022 for each of Singapore’s major trading partner in terms of merchandise trade in 2022 based on Singstat.\n\n\nCode\noptions(ggrepel.max.overlaps = Inf)\n\n\n\n\nCode\ntrade_balance_country %>% \n  mutate(year = factor(year)) %>%\n  filter(year %in% c(2020, 2022)) %>%\n  filter(country %in% c(\"United States\", \"Japan\", \"Mainland China\", \"Hong Kong\", \"Malaysia\", \"Taiwan\", \"Republic Of Korea\", \"Thailand\", \"Indonesia\")) %>%\n  group_by(country, year) %>%\n  summarise(avgtradebalance = round((mean(`tradebalance`)/1000),2)) %>%\n  newggslopegraph(year, avgtradebalance, country,\n                Title = \"Singapore's Trade Balance with major Trading Partners ($ million)\",\n                SubTitle = \"2020-2022\",\n                Caption = \"\")\n\n\n\n\n\nAnalysis:\nSingapore’s trade balance for almost all the major trading partners worsened for almost all the countries except for Hong Kong, Indonesia, Thailand and Malaysia. The ranks remained mostly the same except for the follow countries:\n\nUnited States where Singapore had the 4th highest trade surplus with in 2020 became the 4th highest in terms of trade deficit in 2022, being overtaken by Mainland China and Japan.\nRepublic of Korea which had the 6th highest trade surplus in 2020 became the 2nd highest in terms of trade deficit in 2022, being overtaken by Japan and Malaysia."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#horizon-graph",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#horizon-graph",
    "title": "Take-home Exercise 4",
    "section": "3.4 Horizon graph",
    "text": "3.4 Horizon graph\nWe will create the Horizon graph to visualise how trade balance has decreased (in red) and increased (in blue) between January 2020 to December 2022. I set the origin as 0 since there is positive trade balance (trade surplus) and negative trade balance (trade deficit).\nI added in some vertical lines which represent 5 significant events between 2020-2022:\n\n7 Feb 2020 - In view of Covid-19, Disease Outbreak Response System Condition (DORSCON) was changed to orange which signals that the disease is severe and there is widespread transmission from unknown sources.\n7 April 2020 - Circuit Breaker begins.\n1 February 2021 - Senior Minister of State for Health announced that all polyclinics nationwide would begin offering COVID-19 vaccinations.\n24 February 2022 - Russia invades Ukraine.\n22 April 2022 - MOH announced that from 26 April, Singapore’s DORSCON level would be lowered from Orange to Yellow; limits on groups and safe distancing would no longer be required, with all employees allowed to return to the workplace.\n\nThe code chunk below mutates the period to year-month-date:\n\n\nCode\ntrade_balance_country %>%\n  mutate(`period` = ymd(`period`))\n\n\n# A tibble: 4,032 × 7\n   period     country     import export tradebalance month  year\n   <date>     <chr>        <dbl>  <dbl>        <dbl> <ord> <int>\n 1 2020-01-01 Afghanistan      7   3606         3599 Jan    2020\n 2 2020-02-01 Afghanistan     66   2199         2133 Feb    2020\n 3 2020-03-01 Afghanistan      6   5293         5287 Mar    2020\n 4 2020-04-01 Afghanistan     16   1771         1755 Apr    2020\n 5 2020-05-01 Afghanistan     15   3709         3694 May    2020\n 6 2020-06-01 Afghanistan     72   1752         1680 Jun    2020\n 7 2020-07-01 Afghanistan     11   2656         2645 Jul    2020\n 8 2020-08-01 Afghanistan     38    993          955 Aug    2020\n 9 2020-09-01 Afghanistan     13   2796         2783 Sep    2020\n10 2020-10-01 Afghanistan     19    967          948 Oct    2020\n# … with 4,022 more rows\n\n\nThe code chunk below determines the cut points for the horizon graph:\n\n\nCode\ncutpoints <- trade_balance_country  %>% \n  mutate(\n    outlier = between(\n      tradebalance, \n      quantile(tradebalance, 0.25, na.rm=T)-\n        1.5*IQR(tradebalance, na.rm=T),\n      quantile(tradebalance, 0.75, na.rm=T)+\n        1.5*IQR(tradebalance, na.rm=T))) %>% \n  filter(outlier)\n\nsca <- seq(range(cutpoints$tradebalance)[1], \n           range(cutpoints$tradebalance)[2], \n           length.out = 7)[-4]\n\nround(sca, 2) # The horizon scale cutpoints\n\n\n[1] -187665.00 -122685.67  -57706.33   72252.33  137231.67  202211.00\n\n\ni) By Region\nThe code chunk below creates the Horizon graph to visualise how trade balance has increased and decreased between 2020 to 2022 for each of the regions. I decided not to use the horizon scale above as the visualisation is not clear.\n\n\nCode\ntrade_balance_region %>% \n  ggplot() +\n  geom_horizon(aes(x = period, y=tradebalance), \n               origin = 0, \n               horizonscale = 6)+\n  facet_grid(`region`~.) +\n    theme_few() +\n  scale_fill_hcl(palette = 'RdBu') +\n  theme(panel.spacing.y=unit(0, \"lines\"), strip.text.y = element_text(\n    size = 5, angle = 0, hjust = 0),\n    legend.position = 'none',\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(size=7),\n    axis.title.y = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank()\n    ) +\n    scale_x_date(expand=c(0,0), date_breaks = \"3 month\", date_labels = \"%b%y\") +\n  ggtitle('Trade balance with major trading partners (Jan 2020 to Dec 2022)') +\n  geom_vline(xintercept = as.Date(\"2020-02-07\"), color = \"red\", size = 1) +\n  geom_vline(xintercept = as.Date(\"2020-04-07\"), color = \"red\", size = 1) +\n  geom_vline(xintercept = as.Date(\"2021-02-01\"), color = \"red\", size = 1) +\n  geom_vline(xintercept = as.Date(\"2022-02-24\"), color = \"red\", size = 1) +\n  geom_vline(xintercept = as.Date(\"2022-04-22\"), color = \"red\", size = 1)\n\n\n\n\n\nAnalysis:\nWith the horizontal plot, we can clearly see how the trade balance fluctuated for each region on the same scale, blue representing trade surplus and red representing trade deficit. For example, we see that Singapore has been maintaining a high trade surplus with Asia throughout between July 2020 to January 2022. In the same period, Singapore had fluctuating trade deficit with Europe.\nWe can also see from the red vertical lines that fluctuations seem to happen when there are major significant events. For example, when Russia invaded Ukraine as shown by the second right most vertical line, we can see that trade with Asia and Europe started to fluctuate more greatly.\ni) By Major Trading Partner\nThe code chunk below creates the Horizon graph to visualise how trade balance has increased and decreased between 2020 to 2022 for each of Singapore’s major trading partner in terms of merchandise trade in 2022 based on Singstat. I decided not to use the horizon scale above as the visualisation is not clear.\n\n\nCode\ntrade_balance_country %>% \n  filter(country %in% c(\"United States\", \"Japan\", \"Mainland China\", \"Hong Kong\",     \"Malaysia\", \"Taiwan\", \"Republic Of Korea\", \"Thailand\", \"Indonesia\")) %>%\n  ggplot() +\n  geom_horizon(aes(x = period, y=tradebalance), \n               origin = 0, \n               horizonscale = 6)+\n  facet_grid(`country`~.) +\n    theme_few() +\n  scale_fill_hcl(palette = 'RdBu') +\n  theme(panel.spacing.y=unit(0, \"lines\"), strip.text.y = element_text(\n    size = 5, angle = 0, hjust = 0),\n    legend.position = 'none',\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(size=7),\n    axis.title.y = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank()\n    ) +\n    scale_x_date(expand=c(0,0), date_breaks = \"3 month\", date_labels = \"%b%y\") +\n  ggtitle('Trade balance with major trading partners (Jan 2020 to Dec 2022)')  +\n  geom_vline(xintercept = as.Date(\"2020-02-07\"), color = \"red\", size = 1) +\n  geom_vline(xintercept = as.Date(\"2020-04-07\"), color = \"red\", size = 1) +\n  geom_vline(xintercept = as.Date(\"2021-02-01\"), color = \"red\", size = 1) +\n  geom_vline(xintercept = as.Date(\"2022-02-24\"), color = \"red\", size = 1) +\n  geom_vline(xintercept = as.Date(\"2022-04-22\"), color = \"red\", size = 1)\n\n\n\n\n\nAnalysis:\nWith the horizontal plot, we can clearly see how the trade balance fluctuated for each major trading partner on the same scale, blue representing trade surplus and red representing trade deficit. For example, we see that Singapore has been maintaining a high trade surplus with Hong Kong and high trade deficit with Taiwan throughout the entire period from 2020 to 2022.\nWe can also see from the red vertical lines that fluctuations seem to happen when there are major significant events. For example, this is quite clearly seen by the greater fluctuations around the left 2 red lines when Covid-19 first began."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#braid-graph",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#braid-graph",
    "title": "Take-home Exercise 4",
    "section": "3.2 Braid graph",
    "text": "3.2 Braid graph\nWe will create the Braid graph to visualise how trade balance has changed between trade surplus and trade deficit between January 2020 to December 2022.\ni) By Region\nThe code chunk below creates the Braid graph to visualise how trade balance has changed between 2020 to 2022 for each of regions.\n\n\nCode\nggplot() +\n  geom_line(aes(period, import, linetype = region), data = trade_balance_region) +\n  geom_braid(aes(period, ymin = import, ymax = export, fill = import < export), data = trade_balance_region, alpha = 0.6) +\n  guides(linetype = \"none\", fill = \"none\") +\n  labs(axis.text.x = element_blank(),\n       title = \"Singapore's Trade Balance, 2020-2022\",\n       subtitle = \"Monthly Merchandise Export and Import Trade value with each region\",\n       caption = \"Note: The shaded blue area represents a higher export over import value, indicating a trade surplus.\\n The shaded red area represents a higher import over export value, indicating a trade deficit.\") +\n  xlab(\"Period\") +\n  ylab(\"Trade Balance (Million dollars)\") +\n  facet_grid(~ region) + \n  theme(axis.text.x = element_text(angle = 45))\n\n\n\n\n\nAnalysis:\nFrom the braid graph, we can see that Singapore has maintained mostly a trade surplus with Africa, Asia and Oceania except for some months. Similarly, Singapore has maintained mostly a trade deficit with Europe and European Union except for some months. In terms of trade balance with America, Singapore started off with mostly a trade surplus in 2020 but fluctuated between trade surplus and deficit in 2021 before having mostly a trade deficit in 2022.\nii) By Major Trading Partner\n\n\nCode\ntrade_balance_country_braid <- trade_balance_country %>%\n  filter(country %in% c(\"United States\", \"Japan\", \"Mainland China\", \"Hong Kong\", \"Malaysia\", \"Taiwan\", \"Republic Of Korea\", \"Thailand\", \"Indonesia\")) %>%\n  mutate(import = import/1000) %>%\n  mutate(export = export/1000)\n\n\nThe code chunk below creates the Braid graph to visualise how trade balance has changed between 2020 to 2022 for each of Singapore’s major trading partner in terms of merchandise trade in 2022 based on Singstat.\n\n\nCode\nggplot() +\n  geom_line(aes(period, import, linetype = country), data = trade_balance_country_braid) +\n  geom_braid(aes(period, ymin = import, ymax = export, fill = import < export), data = trade_balance_country_braid, alpha = 0.6) +\n  guides(linetype = \"none\", fill = \"none\") +\n  labs(axis.text.x = element_blank(),\n       title = \"Singapore's Trade Balance, 2020-2022\",\n       subtitle = \"Monthly Merchandise Export and Import Trade value with Major Trading Partners\",\n       caption = \"Note: The shaded blue area represents a higher export over import value, indicating a trade surplus.\\n The shaded red area represents a higher import over export value, indicating a trade deficit.\") +\n  xlab(\"Period\") +\n  ylab(\"Trade Balance (Million dollars)\") +\n  facet_wrap(~ country) + \n  theme(axis.text.x = element_text(angle = 45))\n\n\n\n\n\nAnalysis:\nFrom the Braid graph, we can see that Singapore has consistently maintained a trade surplus with Hong Kong and Indonesia as well as a trade deficit with Taiwan throughout 2020 to 2022. It has maintained mostly a trade surplus with Thailand and mostly a trade deficit with Malaysia except for certain months. Meanwhile, trade balance fluctuated for Mainland China and United States. For Japan and Republic of Korea, trade fluctuated in 2020 to 2021 but became mostly a trade deficit in 2022."
  }
]